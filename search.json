[{"title":"状态量和过程量的区别","path":"/posts/e96a455a/","content":"这篇文章属于知识点笔记，针对状态量和过程的区别，从定义、特征、数学形式三个方面进行了对比，最后通过一个现实生活中爬山的例子进行类比说明。 一、定义对比与典型示例 状态量描述系统在特定时刻或位置的物理属性，其值仅由当前状态决定，与历史路径无关。例如力学中的位置、速度、动量、动能、势能等；热力学中的温度、压强、体积、内能；电磁学中的电场强度、电势。 过程量描述系统状态变化过程的物理量，其值取决于状态变化的路径，与时间或空间累积相关。例如力学中的位移、功、冲量；热力学中的热量、做功；电磁学中的电流做功。 总之，状态量是某个瞬间的快照，而过程量是某个时间段的累积。 二、核心特性对比 1. 对路径的依赖特性 状态量仅仅初始状态和结束状态，过程量不仅与初始状态和结束状态有关，也和具体的运动过程有关。 2. 与时间或时刻的关系 状态量与时刻对应，比如瞬时速度，表示某一时刻位移对时间的微分。过程量与时间间隔对应，比如平均速度是总位移与时间间隔的商。 3. 闭合路径积分 任何状态量的闭合路径积分恒定为 0，比如内能变化在循环过程中归零。过程量的闭合路径积分不一定为 0，而是与具体的闭合曲线形状相关。 三、数学形式对比 1. 微分形式 状态量的微分是全微分，用 ddd 表示，比如内能的变化 dUdUdU。 过程量的微分是非全微分，用 δ\\deltaδ 表示，比如微笑的热量传递 δQ\\delta QδQ 。 2. 积分形式 状态量的积分与路径没有关系，只和初始化状态有关比如内能的变化 ∫abdU=Ub−Ua\\int_{a}^b {dU}=U_{b}-U_{a}∫ab​dU=Ub​−Ua​ 过程量的积分与路径有关，在求积分时需要指定积分路径，比如力的做功 ∫C=F⃗ds\\int_{C}=\\vec{F}ds∫C​=Fds 状态量的闭合路径积分恒定为 0，过程量的闭合路径积分不一定为 0 (与具体的路径方程有关) 偏导数形式 状态量可以定义偏导数，过程量不可定义偏导数，没有意义。 总之，从数学形式上看，状态量是态函数，可以表示为状态空间参数的函数。而过程量就不是一个具体函数了，它是一个路径积分，需要通过参数化路径进行计算。 四、现实世界中的例子 以登山为例，两个人从相同的地方出发，通过不同的路线登上同一个山顶。那么对于个人而言，海拔就是状态量，路程就是过程量。两个人采用不同的方式上山，海拔的变化是相同的，但路程却不一样，这就是状态量的变化只和初末位置有关，过程量的变化与路径有关。两个人都从各自的路径下山，回到最开始出发的地方，海拔的变化为 0，而路程的变化却不为 0，这就是状态量的闭合路径积分为 0，而过程量的闭合路径积分不一定为 0.","tags":["知识点"],"categories":["知识点","物理学"]},{"title":"克劳修斯熵的推导","path":"/posts/53cd2f75/","content":"相关符号说明 符号 含义 QHQ_{H}QH​ , QLQ_{L}QL​ 热量。过程量，单位焦耳，因为温差而传递的能量 THT_HTH​, TLT_{L}TL​ 温度，状态量，单位开尔文 ∮\\oint∮ 环路积分 (闭合路径积分) Δ\\DeltaΔ 变化量，比如 ΔS=Sb−Sa\\Delta S=S_{b}-S_{a}ΔS=Sb​−Sa​ 表示系统从状态 a 到 b 的熵的变化量 δ\\deltaδ 非全微分，针对过程量，比如 δQ\\delta QδQ 表示无限小过程中传递的热量 ddd 全微分，针对状态量，比如 dSdSdS 表示熵的微小变化 状态量 描述系统在某一时刻的某种属性，状态量的变化与路径无关，只和初始和结束位置有关 过程量 描述系统在动态过程中某种属性的累积或者传递，其变化与路径有关 P-V 图 压力-体积图，经典热力学分析工具 上下文 第一次工业革命的本质是烧开水。将煤燃烧产生的热量输入蒸汽机中，水被加热变成蒸汽，蒸汽膨胀产生动能驱动机械做功。在这一过程中能量是守恒的，输入的热量一部分用于做功，另一部分变成热量耗散掉。因此如何提高热机的能量转化效率，让更多的热量转化为做功需要的能量，减少耗散的热量成为了当时的刚需。 法国工程师萨迪·卡诺（Sadi Carnot）试图从理论上解决“热机效率极限”问题，于 1824 年发表《关于火的动力的思考》。卡诺基于热质学基础 (一种错误的、被废弃的理论)，构造了一个理想化的热机模型（卡诺热机），这种纸上的热机取出了现实中一切可能干扰的因素，只由三个部分组成：高温热源 THT_{H}TH​、工质 (气体) 和低温热源 TCT_{C}TC​, 工质从高温热源吸收热量，一部分传递给低温热源，一部分用于做功。 在理想热机的基础上，卡诺构造了一个理想的、完全可逆的循环 (卡诺循环)，经过 Clapeyron 的完善用 P-V 图重新描述如下。 理想热机经过等温吸热、绝热膨胀、等温放热、绝热压缩四个步骤。在 P-V 图中，曲线为等温线，温度为工质温度（与高温热源相同），环路组成的面积就是对外做功。 过程 热交换 温度变化 体积变化 功交换 等温吸热 (1→2) 吸热 Q10Q_1 0Q1​0 恒定 T1T_1T1​ 膨胀 对外做功 W1→2W_{1\\to 2}W1→2​ 绝热膨胀 (2→3) 零 T1→T2T_1 \\to T_2T1​→T2​ 膨胀 对外做功 W2→3W_{2\\to 3}W2→3​ 等温放热 (3→4) 放热 Q20Q_2 0Q2​0 恒定 T2T_2T2​ 压缩 外界做功 W3→4W_{3\\to 4}W3→4​ 绝热压缩 (4→1) 零 T2→T1T_2 \\to T_1T2​→T1​ 压缩 外界做功 W4to1W_{4to 1}W4to1​ 虽然卡诺循环基于的热质学假说是错误的，但是他得到了一个关于热机极限的正确答案（公式 1）。 η=1−∣Q2∣∣Q1∣=1−T2T1(1)\\eta=1-\\frac{|Q_{2}|}{|Q_{1}|}=1-\\frac{T_2}{T_1}\\quad(1) η=1−∣Q1​∣∣Q2​∣​=1−T1​T2​​(1) 热机的能量转化效率的确存在某个极限，而且这个极限与热机本身的物理结构无关，只与高、低温热源的温度差有关。 本文并不会对卡诺热机极限做详细的推演过程，只是把这个卡诺循环和卡诺热机极限公式作为上下文，对麦克斯韦熵进行推导。 推导过程 上文中得到的卡诺热机极限公式经过简单的数学转化，等式的左右进行互换，即得到一个恒等式： ∣Q1∣T2=∣Q2∣T2(2)\\frac{|Q_{1}|}{T_{2}}=\\frac{|Q_{2}|}{T_{2}}\\quad(2) T2​∣Q1​∣​=T2​∣Q2​∣​(2) 因为在卡诺循环中，Q1Q_{1}Q1​ 是吸收热量为正数，而 Q2Q_{2}Q2​ 是放出热量为负数，所以去除绝对值后将这个新的算子放到同一侧，就得到一个新的恒等式： Q1T2+Q2T2=0(3)\\frac{Q_{1}}{T_{2}}+\\frac{Q_{2}}{T_{2}}=0\\quad(3) T2​Q1​​+T2​Q2​​=0(3) 公式 3 对卡诺循环进行了重新的解释中，通过数学构造，在等式中已经出现了热量、温度的商，与熵的定义非常接近了。但此时，它还仅仅是数学的构造，并没有实际的物理意义。 通过离散到连续的推广，可以将可逆系统从卡诺循环推广到任意形状的循环。因为通过构造绝热线和等温线，一个任意形状的可逆循环可以视为无限多个卡诺循环的叠加。因此，对公式 3 进行连续推广后，得到了公式 4 ∑i=1n(δQi,1Ti,1+δQi,2Ti,2)=0(4)\\sum_{i=1}^n\\left(\\frac{\\delta Q_{i,1}}{T_{i,1}}+\\frac{\\delta Q_{i,2}}{T_{i,2}}\\right)=0\\quad(4) i=1∑n​(Ti,1​δQi,1​​+Ti,2​δQi,2​​)=0(4) 当任意可逆循环拆解为 n 个卡诺循环的叠加后，当 n→∞n\\to \\inftyn→∞ 时，每个小型的卡诺循环的吸热和放热 δQi\\delta Q_iδQi​ 趋近于无限小热量，记为 δQrev\\delta Q_{\\mathrm{rev}}δQrev​ 。对于公式 4 求极限，得到积分形态的等式 lim⁡n→∞∑δQiTi=∮δQrevT(5)\\lim_{n\\to\\infty}\\sum\\frac{\\delta Q_i}{T_i}=\\oint\\frac{\\delta Q_\\mathrm{rev}}{T}\\quad(5) n→∞lim​∑Ti​δQi​​=∮TδQrev​​(5) 因为每个可逆卡诺循环中的热温商之和为 0，所以通过公式 4 和公式 5 得到任意可逆循环的热温商的闭合路径积分 ∮δQrevT=0(6)\\oint\\frac{\\delta Q_{\\mathrm{rev}}}{T}=0\\quad(6) ∮TδQrev​​=0(6) 公式 6 即克劳修斯等式 克劳修斯等式表明了一个重要的发现，对于任意一个可逆循环而言，存在一种新的状态函数。因为只有这个函数是状态函数，才能使其闭环积分恒等于 0. 换言之，这个函数与路径无关，只和初始状态和结束状态有关。 举个例子，银行卡的余额就是一个状态量，描述银行卡余额的变化的函数就是状态函数，银行卡余额的变化的计算，只会和初始余额和当前余额有关，而不会与具体的输入和支出相关。假设银行卡初始金额是 100，结束时为 100，那么余额的变化就是 0，无论在这个过程中资金流水时怎样的。 将克劳修斯等式中的闭环积分去掉，留下非全微分的部分，就得到了这种新状态函数的全微分形态, 新状态函数记为 SSS ，全微分形态记为 dSdSdS。克劳修斯将这个新的状态函数命名为 Entropy，这个词来自于希腊语，意思为转化。在中文翻译过程中，翻译者将公式中的热量和温度的比值精准的概括为火之商 ，即为 熵。 dS=δQrevT(7)dS=\\frac{\\delta Q_{rev}}{T} \\quad(7) dS=TδQrev​​(7) ΔS=Sb−Sa=∫abdS=∫abδQrevT(8)\\Delta S =S_{b}-S_{a}=\\int_{a}^{b}dS=\\int_{a}^{b}\\frac{\\delta Q_{rev}}{T} \\quad(8) ΔS=Sb​−Sa​=∫ab​dS=∫ab​TδQrev​​(8) 至此，我们得到了克劳修斯熵的推演。上述过程都是针对可逆循环进行推演的，可逆意味着系统的初始状态和结束状态一致，经过一段过程后，系统恢复到开始之初的状态，在这个过程中没有任何耗散。而对于不可逆循环，因为耗散的存在，热温商的路径积分小于 0。得到克劳修斯不等式公式 9: ∮δQT≤0(9)\\oint\\frac{\\delta Q}{T}\\leq 0 \\quad(9) ∮TδQ​≤0(9) 因此对于不可逆系统 (孤立环境) 而言，熵变大于 0 ΔS≥0(10)\\Delta S \\geq 0 \\quad(10) ΔS≥0(10) 后继（讨论后补充） todo","tags":["熵","克劳修斯"],"categories":["知识点","热力学"]},{"title":"玻尔兹曼熵的推导","path":"/posts/5d325937/","content":"数学符号 符号 含义 ∏\\prod∏ 连乘，如 ! 阶乘 ωi\\omega_{i}ωi​ 能级 Ω\\OmegaΩ 数学工具 排列组合 归一化 上下文 推导过程 后继 引用 [1] 普利高津. 时间、不可逆性与结构 [A]. // 普利高津. 从存在到演化. 上海: 上海译文出版社, 1986: 78-95.","tags":["熵","玻尔兹曼"],"categories":["知识点","统计热力学"]},{"title":"常用数学符号对照表","path":"/posts/5159d9fb/","content":"以下是数学与物理学中常用希腊字母及符号的一站式对照表，包含 LaTeX命令、国际音标、中文发音、数学/物理常用用途，已过滤无法渲染的大写形式，并补充关键数学符号： 希腊字母与常用数学符号对照表 字符 LaTeX命令 中文发音 国际音标 数学/物理常见用途 α\\alphaα $\\alpha$ 阿尔法 /ˈælfə/ 系数、角度、显著性水平（假设检验） β\\betaβ $\\beta$ 贝塔 /ˈbiːtə/ 回归系数、平面角、β衰变（粒子物理） γ\\gammaγ $\\gamma$ 伽马 /ˈɡæmə/ 伽马函数、相对论因子（γ=1/1−v2/c2γ = 1/\\sqrt{1-v^2/c^2}γ=1/1−v2/c2​） δ\\deltaδ $\\delta$ 德尔塔 /ˈdeltə/ 变化量（Δx\\Delta xΔx）、狄拉克δ函数、偏微分算子（∂\\partial∂） ϵ\\epsilonϵ $\\epsilon$ 伊普西龙 /ˈepsɪlɒn/ 无穷小量、介电常数、应变张量 ζ\\zetaζ $\\zeta$ 泽塔 /ˈziːtə/ 黎曼ζ函数、阻尼系数 η\\etaη $\\eta$ 伊塔 /ˈiːtə/ 效率、黏度系数、度量张量（广义相对论） θ\\thetaθ $\\theta$ 西塔 /ˈθiːtə/ 角度、温度（热力学θ）、参数估计量 λ\\lambdaλ $\\lambda$ 兰姆达 /ˈlæmdə/ 波长、特征值、正则化参数 μ\\muμ $\\mu$ 缪 /mjuː/ 均值、摩擦系数、磁导率（电磁学） ν uν $ u$ 纽 /njuː/ 频率、自由度（统计）、中微子 ξ\\xiξ $\\xi$ 克西 /zaɪ/ 或 /ksaɪ/ 随机变量、阻尼比、勒让德函数参数 π\\piπ $\\pi$ 派 /paɪ/ 圆周率（≈3.14）、连乘积符号（∏\\prod∏） ρ\\rhoρ $\\rho$ 柔 /roʊ/ 密度、电阻率、极坐标半径 σ\\sigmaσ $\\sigma$ 西格马 /ˈsɪɡmə/ 标准差、应力张量、电导率 τ\\tauτ $\\tau$ 陶 /tɔː/ 或 /taʊ/ 时间常数、切应力、τ轻子（粒子物理） ϕ\\phiϕ $\\phi$ 斐 /faɪ/ 黄金分割比（φ≈1.618φ≈1.618φ≈1.618）、标量场、相位角 χ\\chiχ $\\chi$ 恺/西 /kaɪ/ 卡方分布（χ2χ^2χ2检验）、电极化率 ψ\\psiψ $\\psi$ 普西 /psaɪ/ 波函数（量子力学）、流函数（流体力学） ω\\omegaω $\\omega$ 欧米伽 /oʊˈmeɪɡə/ 角频率、电阻（Ω）、角速度 变体符号 变体符号 ε\\varepsilonε $\\varepsilon$ 伊普西龙 /ˈepsɪlɒn/ 线性应变张量（区别于标准ε） ϑ\\varthetaϑ $\\vartheta$ 西塔 /ˈθiːtə/ 手写体θ（常见于角度变量） φ\\varphiφ $\\varphi$ 斐 /faɪ/ 电势符号（电磁学）、标量场变体 其他数学符号 其他数学符号 ∫\\int∫ $\\int$ — — 积分运算（定积分、不定积分） ∑\\sum∑ $\\sum$ — — 求和运算（∑i=1nxi\\sum_{i=1}^n x_i∑i=1n​xi​） ∏\\prod∏ $\\prod$ — — 连乘积运算（∏i=1ni=n!\\prod_{i=1}^n i = n!∏i=1n​i=n!） ∂\\partial∂ $\\partial$ — — 偏导数（∂f/∂x\\partial f / \\partial x∂f/∂x） ∞\\infty∞ $\\infty$ — — 无穷大（极限、积分区间） ∇ abla∇ $ abla$ — — 梯度算子（∇f abla f∇f）、散度（∇⋅F abla \\cdot \\mathbf{F}∇⋅F） ∈\\in∈ $\\in$ — — 元素属于集合（x∈Sx \\in Sx∈S） x\\sqrt{x}x​ $\\sqrtx$ — — 平方根（xn\\sqrt[n]{x}nx​表nnn次方根） lim⁡x→a\\lim_{x \\to a}limx→a​ $\\lim_x \\to a$ — — 函数极限（lim⁡x→0sin⁡xx=1\\lim_{x \\to 0} \\frac{\\sin x}{x} = 1limx→0​xsinx​=1）","tags":["Latex"],"categories":["知识点","数学"]},{"title":"AMM的数学原理","path":"/posts/a5238cf/","content":"1. 恒定乘积公式 x⋅y=kx \\cdot y = k x⋅y=k x：池中代币 A 的数量（如 SUI） y：池中代币 B 的数量（如 USDC） k：池的恒定乘积（表示池的总流动性） 任意交易必须满足公式 x⋅y=kx \\cdot y = kx⋅y=k，代币 A 和 B 的比例变化会调整价格，但 k 在没有流动性变动的情况下保持不变。 2. 价格计算 AMM 中的代币价格由两种代币的比例决定 A 的价格（以 B 为单位）： PA=yxP_A = \\frac{y}{x} PA​=xy​ B的价格（以A为单位）： PB=xyP_B=\\frac{x}{y} PB​=yx​ 价格与池中代币的比例直接相关,每次交易都会改变池中代币的比例，从而调整价。 3. Swap 用户通过往池中支付一种代币，来换取另一种代币。 假设用户使用B来购买A，即支付 Δy\\Delta yΔy 个 B 来买入 Δx\\Delta xΔx 个 A，交换之后，交易池中的A和B的数量更新为 x′x{\\prime}x′ , y′y\\primey′ x′=x−Δx,y′=y+Δyx{\\prime} = x - \\Delta x, \\\\ y{\\prime} = y + \\Delta y x′=x−Δx,y′=y+Δy 根据恒定乘积公式 x′⋅y′=x⋅y=kx{\\prime} \\cdot y{\\prime} =x\\cdot y= k x′⋅y′=x⋅y=k 计算swap过程中的数量变化 (x−Δx)⋅(y+Δy)=k(x - \\Delta x) \\cdot (y + \\Delta y) = k (x−Δx)⋅(y+Δy)=k 可计算得到用户输入数量 Δy\\Delta yΔy 的B后，得到的 Δx\\Delta xΔx数量的A Δx=x−ky+Δy\\Delta x = x - \\frac{k}{y + \\Delta y} Δx=x−y+Δyk​ 交易之后价格产生变化 PA′=y′x′P_A{\\prime} = \\frac{y{\\prime}}{x{\\prime}} PA​′=x′y′​ 滑点定义为交易前后价格的相对变化 slip point=PA′−PAPA\\text{slip point} = \\frac{P_A{\\prime} - P_A}{P_A} slip point=PA​PA​′−PA​​ 反之，如果使用A换B，那么根据公式 (x+Δx)⋅(y−Δy)=k(x + \\Delta x) \\cdot (y - \\Delta y) = k (x+Δx)⋅(y−Δy)=k 用户得到的B的数量为 Δy=y−kx+Δx\\Delta y = y - \\frac{k}{x + \\Delta x} Δy=y−x+Δxk​ 4. 添加流动性 流动性提供者向池中增加代币 A 和 B，流动性乘积 k 随之变化。 流动性必须按当前比例添加 Δxx=Δyy\\frac{\\Delta x}{x} = \\frac{\\Delta y}{y} xΔx​=yΔy​ 添加流动性后，新的池状态： x′=x+Δx,y′=y+Δyx{\\prime} = x + \\Delta x, \\quad y{\\prime} = y + \\Delta y x′=x+Δx,y′=y+Δy 添加流动性之后，K值会变大： k′=x′⋅y′=(x+Δx)⋅(y+Δy)k{\\prime} = x{\\prime} \\cdot y{\\prime}=(x + \\Delta x) \\cdot (y + \\Delta y) k′=x′⋅y′=(x+Δx)⋅(y+Δy) 5. 移除流动性 流动性提供者从池中移除代币 A 和 B，流动性乘积 k 减小。 Δxx=Δyy\\frac{\\Delta x}{x} = \\frac{\\Delta y}{y} xΔx​=yΔy​ 移除流动性后，池中的代币数量变化: x′=x−Δx,y′=y−Δyx{\\prime} = x - \\Delta x, \\quad y{\\prime} = y - \\Delta y x′=x−Δx,y′=y−Δy 新的恒定乘积: k′=x′⋅y′=(x−Δx)⋅(y−Δy)k{\\prime} = x{\\prime} \\cdot y{\\prime}=(x - \\Delta x) \\cdot (y - \\Delta y) k′=x′⋅y′=(x−Δx)⋅(y−Δy) 6. 无常损失 在 AMM 池中提供流动性时，与直接持有代币相比，因价格变化而导致的潜在收益损失即为无常损失。 P0P_0P0​：代币 A 相对于 B 的初始价格，即 P0=yxP_0 = \\frac{y}{x}P0​=xy​ P1P_1P1​：价格变化后代币 A 的新价格，即 P1=y′x′P_1 = \\frac{y{\\prime}}{x{\\prime}}P1​=x′y′​ 价格变化比例为r:r:r: r=P1P0r = \\frac{P_1}{P_0} r=P0​P1​​ 在池外直接持有代币的价值： VHODL=x0⋅P0+y0V_{\\text{HODL}} = x_0 \\cdot P_0 + y_0 VHODL​=x0​⋅P0​+y0​ 在池内提供流动性的价值： xLP=kP1,yLP=k⋅P1x_{\\text{LP}} = \\sqrt{\\frac{k}{P_1}}, \\quad y_{\\text{LP}} = \\sqrt{k \\cdot P_1} xLP​=P1​k​​,yLP​=k⋅P1​​ 提供流动性后的总价值为 VAMM=xLP⋅P1+yLPV_{\\text{AMM}} = x_{\\text{LP}} \\cdot P_1 + y_{\\text{LP}} VAMM​=xLP​⋅P1​+yLP​ LP 在 AMM 中提供流动性与直接持有代币价值的相对损失： IL=VAMM−VHODLVHODLIL= \\frac{V_{\\text{AMM}} - V_{\\text{HODL}}}{V_{\\text{HODL}}} IL=VHODL​VAMM​−VHODL​​ 简化公式得到: 无常损失（IL）=2⋅r⋅1r+1−1\\text{无常损失（IL）} = 2 \\cdot \\sqrt{r} \\cdot \\frac{1}{r+1} - 1 无常损失（IL）=2⋅r​⋅r+11​−1 r = 1（价格不变）时，无常损失为 0，r 偏离 1 越多，无常损失越大。","tags":["区块链","交易","uniswap"]},{"title":"《形式语言理论的安全应用》翻译","path":"/posts/fbe65218/","content":"Len Sassaman等人于2011年11月在达特茅斯计算机科学技术学会上所作的学术报告。报告提出了一种基于形式语言理论来提高复杂组合系统的安全性的方法，并阐述了该方法在推动输入验证、安全建模、缩减攻击面、以及在软件设计与编程方法论上的进步。有证据表明，比特币系统的设计参考了这份报告。 摘要 We present an approach to improving the security of complex, composed systems based on formal language theory, and show how this approach leads to advances in input validation, security modeling, attack surface reduction, and ultimately, software design and programming methodology. We cite examples based on real-world security flaws in common protocols representing different classes of protocol complexity. We also introduce a formalization of an exploit development technique, the parse tree differential attack, made possible by our conception of the role of formal grammars in security. These insights make possible future advances in software auditing techniques applicable to static and dynamic binary analysis, fuzzing, and general reverse-engineering and exploit development. -- 我们提出了一种基于形式语言理论的方法，用于提升复杂组合系统的安全性；并阐述了该方法如何推动输入验证、安全建模、攻击面缩减，以及最终在软件设计与编程方法论方面的进步。我们引用了基于常见协议中真实安全漏洞的实例，这些协议代表了不同复杂度的协议类别。此外，基于我们对形式语法在安全中所扮演角色的构想，我们引入了一种漏洞利用开发技术的形式化描述——语法树差分攻击（parse tree differential attack）。这些洞见为未来软件审计技术的进步铺平了道路，这些技术可应用于静态与动态二进制分析、模糊测试（fuzzing）、以及通用的逆向工程与漏洞利用开发。 Our work provides a foundation for verifying critical implementation components with considerably less burden to developers than is offered by the current state of the art. It additionally offers a rich basis for further exploration in the areas of offensive analysis and, conversely, automated defense tools and techniques. 我们的工作为验证关键实现组件奠定了基础，相比现有技术，显著减轻了开发人员的负担。此外，该工作也为攻击性分析以及（与之相对的）自动化防御工具与技术领域的进一步探索提供了丰富的基础。 This report is divided into two parts. In Part I we address the formalisms and their applications; in Part II we discuss the general implications and recommendations for protocol and software design that follow from our formal analysis. 本报告分为两个部分。第一部分阐述形式化方法及其应用；第二部分则讨论基于我们形式化分析得出的、关于协议与软件设计的总体影响与建议。 1 介绍 Composition is the primary engineering means of complex system construction. No matter what other engineering approaches or design patterns are applied, the economic reality is that a complex computing system will ultimately be pulled together from components made by different people and groups of people. 组合是构建复杂系统的主要工程手段。无论采用何种其他工程方法或设计模式，现实情况是，一个复杂的计算系统最终都将由不同人员或团队开发的组件组装而成。 For the traditional division of a system into hardware, firmware, and software, and of software into device drivers, generic OS kernel and its sub-layers, and various application software stacks and libraries the fact of this composition is so obvious that it is commonly dismissed as trivial; how else can one build modern computers and modern software if not in a modular way? Moreover, modularity is supposed to be good for security and reliability, because without them programming would be intractable. 在传统系统分层（硬件、固件、软件）以及软件分层（设备通用操作系统内核及其子层、各类应用软件栈与库）的背景下，这种组合的事实如此显而易见，以至于常被视为微不足道而被忽略；若非采用模块化方式，还能如何构建现代计算机与软件？此外，模块化理应有益于安全性与可靠性，因为缺乏安全性与可靠性，编程将变得难以处理。 However, doing composition securely has emerged as the primary challenge to secure system construction. Security practitioners know that interfaces are attack targets of choice, and that vulnerabilities are often caused by unexpected interactions of features across components; yet the reasons for this are elusive (except perhaps the attacker’s desire for reliable execution of their exploits, which leads them to target the best-described parts of systems with tractable state; still, this does not explain our collective inability to design systems without unwanted feature interactions). 然而，实现安全的组合已成为构建安全系统的核心挑战。安全专家们深知接口是攻击者的首选目标，而漏洞往往源于组件间功能的非预期交互。但其深层原因仍难以捉摸（或许可归因于攻击者追求漏洞利用的可靠执行，故倾向于针对系统状态可控、文档完备的部分，但这仍无法解释为何我们始终难以设计出完全规避非预期功能交互的系统）。 In this paper we argue that we need a new, stronger theoretic understanding of computational units’ composition and of their underlying properties that make it empirically hard to “get it right”, i.e., design systems without vulnerabilities caused by composition. 在本论文中，我们主张需要对计算单元的组成及其底层属性建立一种新的、更强的理论解释，正是这些属性使得实践中难以“实现完美”——即设计出不存在由组合引发漏洞的系统。 We show that there are strong computational-theoretic and formal language-theoretic reasons for the challenges of secure composition, and chart design principles to reduce these challenges. In particular, we show that the hard challenges of safe input handling and secure composition arise due to the underlying theoretically hard or unsolvable (i.e., undecidable) problems that certain protocol designs and implementations essentially require to solve in order to secure them. We posit that the (unwitting) introduction of such problems in the design stage explains the extreme propensity of certain protocols and message formats to yield a seemingly endless stream of “0-day” vulnerabilities despite efforts to stem it, and the empirical hopelessness of “fixing” these protocols and message formats without a fundamental redesign. 我们揭示了安全组合面临的挑战，存在深层的计算理论层面及形式语言理论层面的原因，并规划了降低这些挑战的设计原则。具体而言，安全输入处理与安全组合面临的严峻挑战，源于某些协议设计与实现本质上必须解决的底层理论难题——这些问题在理论上本就难以解决甚至无解（即不可判定）。我们认为，设计阶段（无意的）引入此类问题，导致特定协议和消息格式极易衍生看似无止境的零日漏洞问题（尽管人们努力遏制）。且在缺乏根本性重构的情况下，对这些协议与消息格式进行“修补”在实践中是徒劳的。 We also chart ways to avoid such designs prone to turning into security nightmares for future Internet protocols. Empirically, attempts to solve an engineering problem that implies a “good enough” (or “80%/20%”) solution to the underlying undecidable theory problem are doomed to frustration and failure, which manifests in many ways, such as no amount of testing apparently sufficing to get rid of bugs, or the overwhelming complexity and not-quite-correct operation of the automation or detection tools created to deal with the problem. Thus, avoidingsuch problems in the first place (at the design stage) saves both misinvestment of programming effort and operational costs. 我们还规划了避免此类设计的路径，以防止其演变为未来互联网协议中的安全隐患。实践表明，若工程问题本质上需解决不可判定的理论问题，那么试图以“足够好”（如“80%对比 20%”）的方案应对时，也往往以失败告终。其表现形式多样：例如无论多少测试均无法根除缺陷，或为应对该问题开发的自动化检测工具复杂程度极高且运行并非完全正确。因此，在设计阶段预先规避此类问题，既可避免编程资源的过度投入，也能降低运营成本。 Our argument focuses on the application of fundamental decidability results to the two basic challenges of composed and distributed system construction due to communication between components: safely accepting and handling inputs in every component, and identical interpretation of messages passed between components at every endpoint. In particular, we consider the following two perspectives on composition: 我们的论点主要集中在将基本可判定性结果应用于由组件间通信引起的复合和分布式系统构建的两个基本挑战：在每个组件中安全地接受和处理输入，以及在每个端点上对组件间传递的消息进行相同的解释。特别是，我们考虑了以下两个关于组合的观点： Single-component perspective: A component in a complex system must accept inputs or messages across one or more interfaces. This creates an attack surface, leveraged by an absolute majority of exploitation techniques. We discuss hardening the attack surface of each component against malicious crafted inputs, so that a component is capable of rejecting them without losing integrity and exhibiting unexpected behavior— in short, without being exploited. Multi-component perspective: As components exchange messages, they must ensure that, despite possible implementation differences, they interpret the messages identi-cally. Although this requirement appears to be trivially necessary for correct opera-tion, in reality different implementations of a protocol by different components produce variations, or mutually intelligible dialects, with message semantic differences masked (and therefore ignored) in non-malicious exchanges. A smaller but important class of attack techniques leverages such differences, and can lead to devastating attacks such as those on X.509 and ASN. 1 discussed in this paper. 单组件视角：复杂系统中的一个组件必须通过一个或多个接口接受输入或消息。这会创建一个攻击面，被绝大多数利用技术所利用。我们讨论了如何加固每个组件的攻击面以抵御恶意制作的输入，从而使组件能够在不失去完整性和表现出意外行为的情况下拒绝这些输入——简而言之，不会被利用。 多组件视角：当组件交换消息时，它们必须确保尽管可能存在实现差异，但它们对消息的解释是相同的。虽然这个要求看起来对于正确操作来说是微不足道的，但实际上不同组件对协议的不同实现会产生变化，或者相互可理解的方言，其中消息语义差异在非恶意交换中被掩盖（因此被忽略）。一小部分但重要的攻击技术利用了这种差异，并可能导致毁灭性的攻击，例如本文讨论的对X.509 和 ASN. 1 的攻击。 The importance of these requirements is an empirical fact of the Internet security experience (cf.[1, 2, 3]), which our paper puts in solid theory perspective. We then elaborate the general principles of protocol design that follow from our analysis. 这些要求的重要性是互联网安全经验的实证事实（参见[1, 2, 3]），我们的论文从坚实的理论角度进行了阐述。然后，我们详细阐述了遵循我们分析的协议设计的一般原则。 1.1 本文结构 Our presentation consists of two parts. In Part I we make the case for formal language-theoretic approach to security, and show the direct relevance of various formalisms to prac-tical, state-of-the-art classes of exploits and defences. In Part II we change tack and address protocols designers, developers, and security auditors with a set of recommendations derived from our formal analysis but formulated informally and accessibly. Readers interested in our recommendations may skip the formal arguments in Part I and go straight to Part II’s for their summary. 我们的报告分为两部分。在第一部分，我们为安全的正式语言理论方法进行辩护，并展示各种形式主义与实践中的、最先进的攻击和防御类别的直接相关性。在第二部分，我们改变策略，向协议设计者、开发者和安全审计员提出一系列建议，这些建议源自我们的正式分析，但以非正式且易于理解的方式表述。对我们的建议感兴趣的读者可以跳过第一部分的形式论证，直接阅读第二部分的总结。 We start with the motivation of our approach in Section 2 and review the necessary background formalisms in Section 3. 我们在第 2 节中介绍了我们的方法的动机，并在第 3 节中回顾了必要的背景形式。 Then in Section 4 we explain how these general formalisms apply to exploitation of computing systems, and illustrate this application for several well-known classes of practical exploitation techniques. In doing so, we connect the corresponding classes of attacks with formal language properties of targeted data structures, which provides a novel and definitive way to analyze various suggested defences. 在第 5 节中，我们展示了如何应用形式语言理论技术来实现严格的、非启发式的输入验证。我们从 SQL 验证开始讨论，但也表明同样的方法适用于其他上下文无关的语言，如 PKCS #1 （在第 5.2 节中，我们证明了 PKCS #1确实是上下文相关的 ）。我们还讨论了先前验证方法中的缺陷，并说明为什么这些缺陷对实际安全至关重要。 The discussion of flaws leads to us Section 6, in which we present a new technique for security analysis of differences between mutually intelligible language dialects that arise from implementation differences. This technique, Parse Tree Differential Analysis, proved a powerful tool to enhance code auditing and protocol analysis. 对缺陷的讨论引导我们进入第 6 节，在这一节中，我们提出了一种新的技术，用于分析因实现差异而产生的相互可理解语言方言之间的差异的安全性分析。这种技术，即解析树差异分析，被证明是一种增强代码审计和协议分析的强大工具。 In Section 7, we show that the challenges and failures of IDS/IPS, arguably the most common form of security composition, can be explained via language-theoretic computa-tional equivalence. We conclude Part I with an outline of future work. 在第 7 节中，我们展示了 IDS/IPS 的挑战和失败，可以说是安全组合最常见的形式，可以通过语言理论计算等价性来解释。我们以对未来工作的概述结束了第一部分。 In Part II we recap the observations of Part I and formulate several principles that follow from our analysis in the preceding sections, and discuss their corollaries for designing and implementing protocols securely. 在第二部分中，我们回顾了第一部分的观察结果，并根据前几节的分析制定了几个原则，讨论了它们对安全设计和实施协议的推论。 第一部分：安全与形式语言理论 2 为什么安全需要形式语言理论 We posit that input verification using formal language theoretic methods — whether simply verifying that an input to a protocol constitutes a valid expression in the protocol’s gram-mar or also verifying the semantics of input transformations — is an overlooked but vital component of protocol security, particularly with respect to implementations. Simply put, a protocol implementation cannot be correct unless it recognizes input correctly, and should be considered broken. 我们提出，使用形式语言理论方法进行输入验证——无论是简单地验证协议的输入是否构成协议语法中的有效表达式，还是验证输入转换的语义——是协议安全的一个被忽视但至关重要的组成部分，特别是在实现方面。简而言之，除非协议实现能够正确识别输入，否则它就无法正确运行，并应被视为有缺陷的。 Formal software verification seeks to prove certain safety (“nothing bad happens”) and liveness (“something good happens, eventually”) properties of program computations: if ev-ery computation a program can perform satisfies a particular property, the program is safe (or, respectively, live) with respect to that property[4]. Program verification in the general case is undecidable, and although many approaches to falsification and verification of properties have been developed, unsolved and unsolvable problems with the scalability and completeness of algorithmic verification have prevented formal correctness from displacing testing and code auditing as the industry gold standard for software quality assurance[5]. However, programs that implement protocols — that is to say, routines that operate over a well-defined input language 1 — share one characteristic that can be leveraged to dramati-cally reduce their attack surfaces: their input languages can — and, we posit, should — in general be made decidable and can be decided in a tractable fashion. We show that this requirement of being well-specified and tractably decidable is in fact a crucial pre-requisite of secure design and, in fact, its violation is the source of much of the present-day computer insecurity. 正式软件验证旨在证明程序计算的某些安全（“不会发生坏事”）和活性（“最终会发生好事”）属性：如果程序可以执行的每个计算都满足特定属性，那么该程序在该属性方面是安全的（或分别具有活性）[4]。一般情况下的程序验证是不可判定的，尽管已经开发了许多属性的反证和验证方法，但算法验证的可扩展性和完整性的未解决和无法解决的问题阻碍了正式正确性取代测试和代码审计作为软件质量保证的行业黄金标准[5]。然而，实现协议的程序——也就是说，操作在明确定义的输入语言上的例程——共享一个特性，可以利用这个特性来显著减少它们的攻击面：它们的输入语言通常可以被制成可判定的 (我们主张也应该这么做)，并且可以以一种可行的方式进行判定。我们表明，这种要求是良好指定和可行可判定的，实际上是安全设计的关键先决条件，事实上，其违反是当今计算机不安全的主要来源。 Inputs to system components such as web browsers, network stacks, cryptographic pro-tocols, and databases are formally specified in standards documents, but by and large, implementations’ input handling routines parse the languages these standards specify in an ad hoc fashion. Attacks such as the Bleichenbacher PKCS #1 forgery[6, 7] show what can happen when an ad hoc input-language implementation fails to provide all the prop-erties of the input language as actually specified. In more recent work[8], we have shown that variations among implementations can be exploited to subvert the interoperation of these implementations, and that ambiguity or underspecification in a standard increases the chances of vulnerability in otherwise standards-compliant implementations. 系统组件的输入，如网络浏览器、网络堆栈、加密协议和数据库，在标准文档中被正式规定，但总的来说，实现的输入处理程序以一种临时的方式解析这些标准所规定的语言。诸如 Bleichenbacher PKCS #1伪造 [6, 7]等攻击表明，当一个临时的输入语言实现未能提供实际指定的输入语言的所有属性时会发生什么。在最近的工作[8]中，我们已经证明，实现之间的差异可以被利用来破坏这些实现的互操作性，并且标准中的模糊或未充分规定会增加其他符合标准的实现中出现漏洞的可能性。 On this basis, we argue that “mutually intelligible dialects” of a protocol cannot make guarantees about their operation because the problem Equivalent(L(G)=L(H))Equivalent (L (G)= L (H))Equivalent(L(G)=L(H)) is unde-cidable when G and H are grammars more powerful than deterministic context-free[9, 10]. We also observe that systems that consist of more than one component have inherent, de facto “design contracts” for how their components interact, but generally do not enforce these contracts; SQL injection attacks (hereafter SQLIA), for instance, occur when an at-tacker presents a database with an input query that is valid for the database in isolation, but invalid within the context of the database’s role in a larger application. Since well-specified input languages are in the main decidable 2 (or can be made so), 在此基础上，我们认为协议的“相互可理解方言”无法对其操作做出保证，因为当 G 和 H 是比确定性上下文无关更强大的语法时，问题 Equivalent(L(G)=L(H))Equivalent (\\mathcal{L}(G) = \\mathcal{L}(H))Equivalent(L(G)=L(H)) 是不可判定的[9, 10]。我们还观察到，由多个组件组成的系统具有固有的、事实上的“设计合同”，规定了其组件如何交互，但通常不强制执行这些合同；例如，SQL 注入攻击（以下简称 SQLIA）发生在攻击者向数据库提供一个在孤立状态下对数据库有效的输入查询，但在数据库在更大应用程序中的角色背景下无效的情况下。 由于定义明确的输入语言主要是可判定的（或者可以使其成为可判定的）， There is no excuse for failing to verify inputs with the tools that have existed for this exact purpose for decades: formal parsers. We will examine input verification from several different angles and across multiple computability classes, highlight the unique problems that arise when different programs that interoperate over a standard permit idiosyncratic variations to that standard, and show formally how to restrict the input language of a general-purpose system component (such as a database) so that it accepts only those inputs that it is contractually obligated to accept. 没有理由不使用已经存在了几十年的工具来验证输入：形式解析器。我们将从多个角度和多个可计算性类别来考察输入验证，强调当不同程序在标准上允许特异变化时出现的独特问题，并正式展示如何限制通用系统组件（如数据库）的输入语言，使其仅接受合同义务所要求的输入。 Given the recent advent of provably correct, guaranteed-terminating parser combina-tors[16] and parser generators based on both parsing expression grammars[17] and context-free grammars[18], we hold that the goal of general formal parsing of inputs is within practi-cal reach. Moreover, informal guarantees of correct input recognition are easy to obtain via commonly available libraries and code generation tools; we encourage broader use of these tools in protocol implementations, as incorrect input handling jeopardizes other properties of an implementation. 鉴于最近出现的可证明正确、保证终止的解析器组合子[16]以及基于解析表达文法[17]和上下文无关文法[18]的解析器生成器，我们认为一般形式的输入解析目标在实际应用中是可以实现的。此外，通过常用的库和代码生成工具，很容易获得正确的输入识别的非正式保证；我们鼓励在协议实现中更广泛地使用这些工具，因为不正确的输入处理会危及其他实现属性。 Note. We must distinguish between formal language theoretic security — i.e., a security policy that governs inputs to systems and system components, restricting them to strings in the the formal languages particular to each component, and is enforced through the use of correct parsers for those languages as input handlers — and language-based security[19], which incorporates mechanisms that enforce security policies into the programming lan-guages in which systems and their components are implemented. All of the vulnerabilities we will discuss could appear in programs written in languages that provide language-based security mechanisms. That said, language-based security mechanisms such as proof-carrying code and certifying compilers provide a means by which formal-language-theoretically secure implementations can be verified as such. 注意。我们必须区分形式语言理论安全——即一种安全策略，它管理输入到系统和系统组件的输入，将它们限制在特定于每个组件的形式语言的字符串中，并通过使用这些语言的正确解析器作为输入处理程序来强制执行——和基于语言的安全性[19]，它将强制执行安全策略的机制纳入实现系统及其组件的编程语言中。我们将讨论的所有漏洞都可能出现在提供基于语言的安全机制的语言编写的程序中。也就是说，基于语言的安全机制，如证明携带代码和认证编译器，提供了一种方法，可以验证形式语言理论安全的实现是否如此。 3 背景形式化 3.1 可计算界限及乔姆斯基文法层次结构 Noam Chomsky classified formal grammars in a containment hierarchy according to their expressive power, which correlates with the complexity of the automaton that accepts exactly the language a grammar generates, as shown in Fig. 1[20]. 诺姆·乔姆斯基根据表达能力将形式文法分类为一个包含层次结构，这与接受文法生成的语言的自动机的复杂性相关，如图 1 所示[20]。 无歧义上下文无关文法 - 确定性下推自动机 模糊上下文无关文法 - 非确定性下推自动机 上下文相关的语法/语言 - 线性有界自动机 递归可枚举语言、无限制语法 - 图灵机 Within this hierarchy, one class of automaton can decide an equivalently powerful lan-guage or a less powerful one, but a weaker automaton cannot decide a stronger language. (E.g., a pushdown automaton can decide a regular language, but a finite state machine can-not decide a context-free language.) Thus, formal input validation requires an automaton (hereafter, parser) at least as strong as the input language. It is a useful conceit to think of a protocol grammar in terms of its place in the Chomsky hierarchy, and the processor and code that accept input in terms of machine strength, while being conscious of their equivalence. 在这个层次结构中，一类自动机可以决定一个同等强大的语言或一个较弱的语言，但较弱的自动机不能决定一个更强的语言。（例如，一个堆栈自动机可以决定一个正则语言，但有限状态机不能决定一个上下文无关语言。）因此，正式的输入验证需要一个至少与输入语言一样强大的自动机（以下称为解析器）。从乔姆斯基层次结构的角度来思考协议语法，并将接受输入的处理器和代码视为机器强度，同时意识到它们的等价性，这是一个有用的假设。 Recursively enumerable languages are undecidable, which presents a serious implemen-tation problem: the Turing machine that accepts a given recursively enumerable language, or recognizer 3 for that language, halts in an accepting state on all strings in the language, but either rejects or fails to halt on inputs not in the language. All weaker language classes are decidable; their equivalent automata always terminate in an accept or reject state[20, 10]. An unrestricted protocol grammar is thus a security risk, since malicious input could cause its parser to fail to halt — a syntactic denial of service — or perform arbitrary computa-tion. The rubric we derive from these bounds on expressiveness — “use a sufficiently strong parser for an input language, but no stronger” — is echoed in the W 3 C’s “Rule of Least Power”: “Use the least powerful language suitable for expressing information, constraints or programs on the World Wide Web.”[21] 递归可枚举语言是不可判定的，这带来了一个严重的实现问题：接受给定递归可枚举语言的图灵机，或者该语言的识别器 3，在所有语言字符串上都会在接收状态中停止，但是要么拒绝，要么无法在不属于该语言的输入上停止。所有较弱的语言类都是可判定的；它们的等价自动机总是在接受或拒绝状态终止[20, 10]。因此，无限制的协议语法是一种安全风险，因为恶意输入可能导致其解析器无法停止——一种语法拒绝服务——或者执行任意计算。我们从这些表达能力的界限中得出的规则——“为输入语言使用足够强大的解析器，但不要更强”——与 W 3 C 的“最小权力规则”相呼应：“使用最适合在万维网上表达信息、约束或程序的最弱语言。”[21] Parsers also exhibit certain safety and liveness properties (after Lamport[4]). Soundness is a safety property; a sound parser only accepts strings in its corresponding language, and rejects everything else. Completeness is a liveness property; a complete parser accepts every string in its corresponding language. Termination is also a safety property; a terminating parser eventually halts on every string presented to it, whether that string belongs to its language or not. 解析器还表现出某些安全性和活性属性（根据 Lamport[4]）。正确性是一种安全性属性；一个正确的解析器只接受其对应语言中的字符串，而拒绝其他所有内容。完整性是一种活性属性；一个完整的解析器接受其对应语言中的每个字符串。终止性也是一种安全性属性；一个终止的解析器最终会在呈现给它的每个字符串上停止，无论该字符串是否属于其语言。 Two other decidability problems influence our analysis: the context-free equivalence and containment problems. Given two arbitrary context-free grammars, GGG and HHH, both L(G)=L(H)\\mathcal{L}(G) = \\mathcal{L}(H)L(G)=L(H) and L(G)⊆L(H)\\mathcal{L}(G) \\subseteq \\mathcal{L}(H)L(G)⊆L(H) are undecidable[10], except for a particular construction detailed in[22]. The context-free grammars form two disjoint sets: deterministic and non-deterministic, corresponding to deterministic and non-deterministic pushdown automata respectively. All unambiguous context-free grammars are deterministic[23], and the equiv-alence problem for deterministic CFGs is decidable though the containment problem is not. 另外两个可判定性问题影响了我们的分析：上下文无关等价和包含问题。给定两个任意的上下文无关文法，GGG 和 HHH，L(G)⊆L(H)\\mathcal{L}(G) \\subseteq \\mathcal{L}(H)L(G)⊆L(H) 和 L(G)⊆L(H)\\mathcal{L}(G) \\subseteq \\mathcal{L}(H)L(G)⊆L(H) 都是不可判定的[10]，除了在[22]中详细描述的特定构造。上下文无关文法形成了两个不相交的集合：确定性和非确定性，分别对应于确定性和非确定性下推自动机。所有无歧义的上下文无关文法都是确定性的[23]，并且确定性 CFG 的等价问题是可判定的（尽管包含问题是不可判定的）[9]。 Any grammar in which the value of an element in the string influences the structure of another part of the string is at least context-sensitive[24]. This applies to most network protocols and many file formats, where length fields, e.g. the Content-Length field of an HTTP header[25] or the IHL and Length fields of an IPv 4 datagram[26], are commonplace. Programming language grammars that support statements of the form “if B 1 then if B 2 then S 1 else S 2”, e.g. Javascript[27], are nondeterministic context-free (at best) due to the ambiguity the “dangling else” problem introduces[28]; if the shift-reduce conflict is resolved without adding braces or alternate syntax (e.g. elif or end if), the resulting grammar is non-context-free. Conveniently, the PostgreSQL, SQLite, and MySQL database engines all use LR grammars, which are deterministic context-free[29]. Membership tests for certain subclasses of LR (e.g. LALR, LR (k), etc.) and approximate ambiguity detection methods exist[30]; however, determining whether an arbitrary CFG is unambiguous is undecidable[31]. 任何一种语法，其中字符串中元素的值影响结构的字符串的另一部分至少是上下文相关的[24]。这适用于大多数网络协议和许多文件格式，其中长度字段很常见，例如 HTTP 头中的 Content-Length 字段[25]或 IPv 4 数据包中的 IHL 和 Length 字段[26]。支持“如果 B 1 则如果 B 2 则 S 1 否则 S 2”形式语句的编程语言语法，例如 Javascript[27]，由于“悬空 else”问题引入的歧义，是非确定性上下文无关的（最多）；如果在不添加括号或替代语法（例如 elif 或 end if）的情况下解决移位-归约冲突，则生成的语法是非上下文无关的。方便的是，PostgreSQL、SQLite 和 MySQL 数据库引擎都使用 LR 语法，这是确定性上下文无关的[29]。存在某些 LR 子类（例如 LALR、LR (k) 等）的成员测试和近似歧义检测方法[30]；然而，确定任意 CFG 是否无歧义是不可判定的[31]。 3.2 从安全角度建模 In 1948, Claude Shannon proposed a block-diagram model to describe systems which gen-erate information at one point and reproduce it elsewhere[32]. In it, an information sourcegenerates messages (sequences drawn from an alphabet); a transmitter encodes each mes-sage into a signal in an appropriate form for the channel over which it can pass data, thensends it; a receiver decodes signals into reconstructed messages; and a destination associatedwith the receiver interprets the message. The engineering problem of maximizing encodingefficiency motivated Shannon’s work; he regarded the meanings of messages as outside thescope of this transmission model. Nevertheless, social scientists such as Schramm[33] andBerlo[34] expanded the transmission model to incorporate semantic aspects of communi-cation. Schramm recast the destination as an interpreter, which takes actions accordingto the decoded message’s semantic content, and replaced Shannon’s one-way message pathwith a bidirectional one; Berlo emphasized the difficulty of converting thoughts into wordsand back, particularly when sender and receiver differ in communication ability. Theseinsights, combined with Hoare’s axiomatic technique for defining programming languagesemantics[35], have surprising implications for the practice of computer security. 1948 年，克劳德·香农提出了一种方框图模型来描述在某一点生成信息并在其他地方再现的系统[32]。在这个模型中，一个信息源生成消息（从字母表中抽取的序列）；一个发送器将每个消息编码成适合于通道的数据形式，然后发送它；一个接收器将信号解码为重构的消息；与接收器相关联的目的地解释消息。最大化编码效率的工程问题激发了香农的工作；他认为消息的意义超出了这个传输模型的范围。然而，像施拉姆[33]和伯洛[34]这样的社会科学家扩展了传输模型以包含通信的语义方面。施拉姆将目的地重新定义为解释者，根据解码消息的语义内容采取行动，并用双向路径替换了香农的单向消息路径；伯洛强调了将思想转化为语言并反过来的困难，特别是当发送者和接收者的沟通能力不同时。这些见解，结合霍尔用于定义编程语言语义的公理技术[35]，对计算机安全实践产生了惊人的影响。 When a destination extracts a different meaning from a decoded message than the one the source intended to transmit, the actions the destination performs are likely to diverge— perhaps significantly — from what the source expected. In human communication, it is difficult to evaluate whether an unexpected response signifies a failure in transmission of meaning or that the source’s assessment of what behavior to expect from the destination was wrong. In computer science, however, we can make formal assertions about the proper-ties of destinations (i.e., programs), reason about these properties, and demonstrate that a program is correctup to decidability[35]. When a destination program’s semantics and im-plementation are provably correct, “whether or not it carries out its intended function”[35] is a question of whether the destination received the intended message. If a verified destina-tion’s response to a source’s message M does not comport with the response that deduction about the program and M predict, the receiver has decoded something other than the M that the transmitter encoded. In practice, this situation is not infrequent between different implementations of a protocol. 当一个目的地从解码的消息中提取出与源意图传输的不同含义时，目的地执行的动作可能会偏离——可能显著偏离——源的预期。在人类交流中，很难评估意外的反应是表示意义传递失败还是源对目的地应表现出的行为的评估错误。然而，在计算机科学中，我们可以对目的地（即程序）的属性做出正式的断言，对这些属性进行推理，并证明程序在可判定性上是正确的[35]。当目的地程序的语义和实现被证明是正确时，“它是否执行其预期功能”[35]的问题就变成了目的地是否接收到预期消息的问题。如果经过验证的目的地对源消息 M 的响应不符合关于程序和 M 的推论所预测的响应，接收器解码的内容就不是发送器编码的 M。实际上，这种情况在不同协议实现之间并不罕见。 Berlo’s and Schramm’s adaptations rightly drew criticism for their focus on encoding and decoding, which implied the existence of some metric for equivalence between one per-son’s decoder and the inverse of another person’s encoder. However, in transmissions over computer networks, where both source and destination are universal Turing machines, we can test the equivalence of these automata if they are weak enough; if they are nondetermin-istic context-free or stronger, their equivalence is undecidable. Points of encoder-decoder inequivalence — specifically, instances where, for a message M, an encoding function E, and a decoding function D\\mathcal{D}D , D(E(M))≠M\\mathcal{D}(\\mathcal{E}(M)) eq MD(E(M))=M — can cause the destination to take some action that the source did not anticipate. An attacker who can generate a signal E (M) such that D (E (M)) /= M can take advantage of this inequivalence. Indeed, many classic exploits, such as buffer overflows, involve crafting some E (M) — where the meaning of M, if any, is irrelevant 4 — such that applying D to E (M), or passing D (E (M)) as an input to the destination, or both, elicits a sequence of computations advantageous to the attacker (e.g., opening a remote shell). 伯洛和施拉姆的改编因其对编码和解码的关注而受到批评，这暗示了一个人的解码器与另一个人的编码器的逆向之间存在某种等价度量。然而，在计算机网络传输中，源和目的地都是通用图灵机，如果这些自动机足够弱，我们可以测试它们的等价性；如果它们是非确定性上下文无关或更强，则它们的等价性是不可判定的。编码器-解码器不等价的点——具体来说，对于一个消息 M、一个编码函数 EEE 和一个解码函数 DDD，当 D(E(M))≠M\\mathcal{D}(\\mathcal{E}(M)) eq MD(E(M))=M 时——可能导致目的地采取源未预料到的某些行动。能够生成信号 E(M)E (M)E(M) 使得 D(E(M))≠MD (E (M)) eq MD(E(M))=M 的攻击者可以利用这种不等价性。事实上，许多经典漏洞，如缓冲区溢出，都涉及构造一些 E(M)E (M)E(M) ——其中 MMM 的意义（如果有）是无关紧要的 4——使得将 DDD 应用于 E(M)E (M)E(M)，或将 D(E(M))D (E (M))D(E(M)) 作为输入传递给目的地，或者两者兼而有之，引发对攻击者有利的一系列计算（例如，打开远程 shell）。 Naturally, an attacker who can alter E (M) in the channel, or who can modify M before its encoding, can also elicit unexpected computation. The former is a man-in-the-middle attack; the latter is an injection attack. Both affect systems where the set of messages that the source can generate is a subset of those on which the destination can operate. 自然地，一个能够在通道中改变 E(M)E (M)E(M) 的攻击者，或者在编码前修改 M 的攻击者，也可以引发意外的计算。前者是中间人攻击；后者是注入攻击。这两种攻击都会影响到源可以生成的消息集是目标可以操作的消息集的子集的系统。 Note that we do not consider situations where D (E (M))= M but different destinations respond to M with different actions; these constitute divergent program semantics, which is relevant to correctness reasoning in general but outside the scope of this work. We are only interested in the semantics of D and E. 请注意，我们不考虑 D (E (M))= M 但不同目的地对 M 做出不同反应的情况；这些构成了不同的程序语义，这与一般正确性推理相关，但不在本工作的范围内。我们只对 D 和 E 的语义感兴趣。 4 利用作为意外计算 Sending a protocol message is a request for the receiving computer to perform computation over untrusted input. The receiving computer executes the decoding (parsing) algorithm D (M), followed by (i.e., composed with) subsequent operations conditional on the result of D; thus, E (M)→ D (E (M)) · C (D (E (M))). It is never the case that simply parsing an input from an untrusted source should result in malicious code execution or unauthorized disclosure of sensitive information; yet, this is the basis of most effective attacks on modern networked computer systems, specifically because they permit, though they do not expect, the execution of malicious algorithms when provided the corresponding input. That this computation is unexpected is what leads to such vulnerabilities being considered exploits, but ultimately, the problem constitutes a failure in design. Whether implicitly or explicitly, designers go to work with a contract[37] in mind for the behavior of their software, but if the code does not establish and enforce preconditions to describe valid input, many types of exploits are possible. This behavior is especially harmful across layers of abstraction and their correspond-ing interfaces, since in practice these layer boundaries become boundaries of programmers’competence. 发送协议消息是请求接收计算机对不可信输入进行计算。接收计算机执行解码（解析）算法 D (M)，然后根据 D 的结果进行后续操作；因此，E (M)→ D (E (M)) · C (D (E (M)))。从不可信来源简单地解析输入不应该导致恶意代码执行或敏感信息的未经授权的披露；然而，这正是现代网络计算机系统中最有效的攻击的基础，特别是因为它们允许（尽管不期望）在提供相应输入时执行恶意算法。这种计算的意外性导致这些漏洞被视为利用，但最终，问题在于设计上的失败。无论隐式还是显式，设计师在考虑他们的软件行为合同时开始工作，但如果代码没有建立和强制预条件来描述有效输入，许多类型的利用都是可能的。 这种行为在抽象层及其对应的接口之间尤其有害，因为在实践中，这些层的边界成为了程序员能力的边界。 4.1 注入攻击 Injection attacks target applications at points where one system component acquires input from a user in order to construct an input for another component, such as a database, a scripting engine, or the DOM environment in a browser. The attacker crafts an input to the first component that results in the constructed input producing some computation in the second component that falls outside the scope of the operations the system designer intended the second component to perform. Some examples: 注入攻击针对的是应用程序中一个系统组件从用户获取输入以构建另一个组件（如数据库、脚本引擎或浏览器中的 DOM 环境）的输入点。攻击者精心设计对第一个组件的输入，使得构建的输入在第二个组件超出了系统设计者预期的第二个组件执行的操作范围。一些例子： Example 1 (Command injection) Functions such as system () in PHP, Perl, and C; nearly all SQL query execution functions; and Javascript’s eval () take as argument a string representation of a command to be evaluated in some execution environment (here, the sys-tem shell, a database engine, and the Javascript interpreter respectively). Most such envi-ronments support arbitrary computation in their own right, though developers only intend their systems to use a very limited subset of this functionality. However, when these func-tions invoke commands constructed from unvalidated user input, an attacker can design an input that appends additional, unauthorized commands to those intended by the developer —which the environment dutifully executes, using the same privileges afforded to the desired commands[38]. 示例 1（命令注入）：PHP、Perl 和 C 中的 system () 等函数；几乎所有 SQL 查询执行函数；以及 Javascript 的 eval ()，它们都接受一个字符串形式的命令作为参数，这些命令将在某个执行环境中进行评估（在这里，分别是系统 shell、数据库引擎和 Javascript 解释器）。大多数这样的环境本身支持任意计算，尽管开发人员只打算让他们的系统使用其中非常有限的功能子集。然而，当这些函数调用由未经验证的用户输入构造的命令时，攻击者可以设计一个输入，将额外的、未经授权的命令附加到开发人员预期的命令上——环境会忠实地执行这些命令，使用与所需命令相同的权限[38]。 Example 2 (HTTP parameter pollution) RFC 3986[39] observes that the query com-ponent of a URI often contains “key=value” pairs that the receiving server must handle, but specifies nothing about the syntax or semantics of such pairs. The W 3 C’s form-urlencoded media type[40] has become the de facto parameter encoding for both HTTP GET query strings and HTTP POST message bodies, but parameter handling semantics are left to im-plementer discretion. Idiosyncratic precedence behaviour for duplicate keys, in a query string or across input channels, can enable an attacker to override user-supplied data, control web application behaviour, and even bypass filters against other attacks[41]. 示例 2（HTTP 参数污染）RFC 3986[39]指出，URI 的查询组件通常包含“key=value”对，接收服务器必须处理这些对，但并未规定这些对的语法或语义。W 3 C 的 form-urlencoded 媒体类型[40]已成为 HTTP GET 查询字符串和 HTTP POST 消息体的事实上的参数编码，但参数处理语义则由实现者自行决定。在查询字符串中或跨输入通道中，对于重复键的特异优先级行为可以使攻击者覆盖用户提供的数据，控制 Web 应用程序的行为，甚至绕过针对其他攻击的过滤器[41]。 All types of injection leverage a weak boundary between control and data channels[42] to modify the structure, and thereby the execution semantics, of an input to an application component[22, 42]. Halfond et al[43] enumerate many heuristic injection defenses; in section 5.1 we describe parse tree validation, a verifiable defense technique. There are several categories of defense against injection: escaping, which attempts to transform user input that might alter the structure of a subsequently constructed input into a string-literal equivalent; tainting, which flags user input as untrusted and warns if that input is used unsafely; blacklisting, which attempts to identify and reject malicious inputs; programmatic abstraction, which provides control channel access through an API and relegates user input to the data channel[43] Another technique, parse tree validation, passes constructed inputs through a validator that parses them, compares the resulting parse tree to a set of acceptable candidate parse trees, and rejects inputs whose structure is not in that set. 所有类型的注入攻击都利用了控制和数据通道之间的薄弱边界[42]，以修改输入到应用程序组件的结构，从而改变其执行语义[22, 42]。Halfond 等人[43]列举了许多启发式注入防御方法；在第 5.1 节中，我们描述了一种可验证的防御技术——解析树验证。针对注入攻击的防御有几种类别：转义，它试图将可能改变随后构造的输入结构的用户输入转换为字符串字面量等价物；标记，它将用户输入标记为不可信，并在该输入被不安全地使用时发出警告；黑名单，它试图识别并拒绝恶意输入；程序抽象，它通过 API 提供对控制通道的访问，并将用户输入降级到数据通道[43]。另一种技术，解析树验证，将构造的输入通过一个解析器进行验证，将生成的解析树与一组可接受的候选解析树进行比较，并拒绝结构不在该集合中的输入。 4.2 其他攻击面 Other attack vectors blur the boundaries between control and data channels in subtler ways; rather than targeting the higher-level languages that injection exploits, they take advantage of input handling failure modes to alter the machine code or bytecode in an already-executing process. Many such attacks, e.g. shellcode attacks[44], contain a sequence of opcodes that are written to a location within the process’s address space and executed by means of a jump from an overwritten stack frame return address; other techniques, such as return-to-libc[45] and its generalization, return-oriented programming[46, 47], overwrite the return address to point to a function or a code fragment (a.k.a. “gadget”, e.g., in the program’s code section, or in a library such as libc) not meant to be a part of the stack-backed control flow and adjacent memory to contain any arguments the attacker wants to pass to that function, enabling arbitrary code execution even on platforms with non-executable stacks[48]. 其他攻击向量以更微妙的方式模糊了控制和数据通道之间的界限；它们不是针对注入漏洞所利用的高级语言，而是利用输入处理故障模式来改变已经在执行过程中的机器代码或字节码。许多这样的攻击，例如 shellcode 攻击[44]，包含一系列操作码，这些操作码被写入进程地址空间内的某个位置，并通过覆盖堆栈帧返回地址的跳转来执行；其他技术，如 return-to-libc[45]及其泛化形式，return-oriented programming[46, 47]，会覆盖返回地址，使其指向一个函数或代码片段（也称为“小工具”，例如在程序的代码段中，或在 libc 等库中），这些函数或代码片段并非旨在成为基于堆栈的控制流的一部分，相邻内存则包含攻击者想要传递给该函数的任何参数，即使在具有非可执行堆栈的平台上也能实现任意代码执行[48]。 Example 3 (Buffer Overflows) When a function designed to write data to a bounded region of memory (a buffer) attempts to write more data than the buffer can contain, it may overwrite the values of data in adjacent memory locations — possibly including the stack frame return address[49] or a memory allocator’s heap control structures[50, 51, 52]. Constraining such a function’s input language to values that the function cannot transform into data larger than the buffer can prevent an overflow, although the presence of format string arguments (see below) can complicate matters. 示例 3（缓冲区溢出）：当一个设计用于向内存的有界区域（缓冲区）写入数据的函数试图写入比缓冲区能容纳更多的数据时，它可能会覆盖相邻内存位置的数据值——可能包括堆栈帧返回地址[49]或内存分配器的堆控制结构[50, 51, 52]。通过将该函数的输入语言限制为函数无法转换成大于缓冲区的数据的值，可以防止溢出，尽管格式字符串参数的存在（见下文）可能会使问题复杂化。 Example 4 (Format String Attacks) Certain C conversion functions permit placehold-ers in their format string argument which interpolate subsequent arguments into the stringthe function constructs. If a process allows an attacker to populate the format string argu-ment, he can include placeholders that let him inspect stack variables and write arbitraryvalues to arbitrary memory locations[53]. Other languages that support format strings ex-hibit similar vulnerabilities[54], and languages implemented in C, such as PHP, can succumbindirectly if unsafe input reaches a format string argument in the underlying implementa-tion[55]. Fortunately, C’s placeholder syntax is regular, and since the regular languages areclosed under complement[10], it is easy to define a positive validation routine[43] whichadmits only user input that contains no formatting placeholders. 示例 4（格式字符串攻击）：某些 C 转换函数允许在其格式字符串参数中使用占位符，这些占位符将后续参数插入到函数构造的字符串中。如果一个进程允许攻击者填充格式字符串参数，他可以包含占位符，从而让他检查堆栈变量并将任意值写入任意内存位置[53]。其他支持格式字符串的语言也表现出类似的漏洞[54]，而用 C 实现的语言，如 PHP，如果危险输入到达底层实现中的格式字符串参数，也会间接受到影响[55]。幸运的是，C 的占位符语法是规则的，由于规则语言在补集下是封闭的[10]，因此很容易定义一个正向验证例程[43]，该例程仅接受不包含格式化占位符的用户输入。 Thus, we see that hardening input routines, so that they do not provide subsequent operations with arguments that violate those operations’ preconditions or fail in ways that permit an attacker to execute arbitrary code, is at the core of all defensive coding practices. We now examine in detail the mechanics of validating input languages of various classes in a provable and tractable fashion. 因此，我们看到，强化输入例程，使其不会为后续操作提供违反这些操作的先决条件或以允许攻击者执行任意代码的方式失败的参数，是所有防御性编码实践的核心。我们现在详细研究以可证明和可行的方式验证各种类别的输入语言的机制。 5 可证明正确的输入验证 Despite the majority of work in this area focusing on injection attacks, formal languagetheoretic input validation offers security protections against a much wider range of exploits. Any attack that exploits a process’s parsing such that it accepts an input that does notconform to the valid grammar of the intended protocol can and should be prevented viastrict validation of inputs. 5 尽管该领域的大部分工作都集中在注入攻击上，但形式语言理论的输入验证提供了更广泛的针对各种漏洞的安全保护。任何利用进程解析的攻击，使其接受不符合预期协议有效语法的输入，都可以也应该通过严格的输入验证来防止。5 5.1 注入攻击和上下文无关语法树验证 In 2005, Dejector[22] presented a context-free parse tree validation approach to preventing SQLIA. 6 It introduced a formal construction for restricted sublanguages of SQL 7; using this approach, validating an SQL query consists of testing it for membership in the sublanguage. Given a set of known-good queries and the formal grammar for the appropriate dialect of SQL, Dejector transforms the SQL grammar into a subgrammar that contains only the rules required to produce exactly the queries in the known-good set 8. Strings recognized by the subgrammar are guaranteed to be structurally identical to those in the known-good set — a validity metric attested throughout the injection attack literature[59, 58]. The subgrammar is then used with a parser generator such as bison or ANTLR to produce a recognizer for the sublanguage. Notably, this automaton is exact rather than heuristic (as in[56]) or approximate (as in[60] and[61]), and has the optimizing effect of comparing inbound queries to all known-good structures simultaneously. 2005 年，Dejector[22]提出了一种上下文无关的解析树验证方法来防止 SQL 注入攻击。它引入了一种用于限制 SQL 子语言的形式化构造；使用这种方法，验证一个 SQL 查询包括测试它是否属于该子语言。给定一组已知良好的查询和适当的 SQL 方言的形式语法，Dejector 将 SQL 语法转换为仅包含这些良好查询的子语法。规则要求生成与已知良好集合中完全相同的查询 8。子语法识别的字符串保证在结构上与已知良好集合中的字符串相同——这是在整个注入攻击文献[59, 58]中得到证实的有效性指标。然后，使用像 bison 或 ANTLR 这样的解析器生成器来生成子语言的识别器。值得注意的是，这个自动机是精确的，而不是启发式的（如[56]中）或近似的（如[60]和[61]中），并且具有优化效果，可以同时将传入的查询与所有已知良好的结构进行比较。 Subsequent research has produced improvements to the original approach, primarily fo-cused on identifying the initial legitimate-query set and automatically integrating validation into an application. Unfortunately, each of these efforts suffers from flaws which prevent them from guaranteeing correct validation or correct application behavior. These include: Insufficiently strong automaton Validator and database use different grammars 后续的研究对原始方法进行了改进，主要集中在识别初始合法查询集，并自动将验证集成到应用程序中。不幸的是，这些努力都存在缺陷，无法保证正确的验证或正确应用程序行为。这些缺陷包括： 5.1.1 自动机不够强大 Several automata-based validators[60, 61, 62, 63, 64] model the set of acceptable queries using a finite state machine, following the approach of Christensen et al.[65], wherein static analysis of calls to methods that issue SQL queries yields a flow graph representing possible generated strings, which is then widened to a regular language for tractability. Sun and Besnozov identify cases where such FSA models generate false-positive reports[66], and indeed Wassermann et al. concede that their approximation of the set of legitimate query strings is overly permissive. However, they assert: In practice, we do not find a function that concatenates some string, the return value of a recursive call to itself, and another string (which would construct a language such as{(na) n}), so this widening step does not hurt the precision of the analysis. 几个基于自动机的验证器[60, 61, 62, 63, 64]使用有限状态机来模拟可接受查询的集合，遵循 Christensen 等人[65]的方法，其中对发出 SQL 查询的方法调用进行静态分析，产生一个表示可能生成的字符串的流图，然后将其扩展为正则语言以提高可处理性。Sun 和 Besnozov 确定了某些情况下，这种 FSA 模型会产生误报[66]，实际上 Wassermann 等人也承认他们对合法查询字符串集的近似过于宽松。然而，他们断言: 在实践中，我们没有找到一个函数，它将一些字符串、递归调用自身的返回值以及另一个字符串（这将构建一种语言，如{(na) n}）连接起来，因此这个扩展步骤不会损害分析的准确性。 We examined the bison grammar that generates the PostgreSQL parser and, regrettably, discovered four such functions. The right-hand sides of the production rules select with parens and joined table contain the precise parenthesis-balancing syntax that Wassermann et al. claimed not to find in practice. Unbalanced parentheses alone are sufficient to trigger those vulnerabilities classified in the taxonomy of Halfond et al. as “illegal/logically incorrect queries”[43]. 我们检查了生成 PostgreSQL 解析器的 bison 语法，并遗憾地发现了四个这样的函数。产生规则的右侧选择带有括号和连接表的部分包含 Wassermann 等人声称在实践中未找到的精确括号平衡语法。不平衡的括号本身足以触发 Halfond 等人分类为“非法/逻辑上不正确的查询”的那些漏洞[43]。 The other functions we found are subtler and more troubling. The right-hand side of the production common table expr, which can precede SELECT, INSERT, UPDATE or DELETE statements, contains the sequence ’(’PreparableStmt ’)’; a PreparableStmt is itself a SELECT, INSERT, UPDATE or DELET statement. Furthermore, the a expr and c expr productions, which recognize unary, binary, and other expressions — such as x N OT NULL, x LIKE y, and all arithmetic expressions— are mutually recursive. These productions appear throughout the PostgreSQL grammar, and are the grammatical targets of nearly every category of SQLIA, since user-supplied inputs typically correspond to productions on the right-hand side of an a expr. 我们发现的其他功能更加微妙和令人担忧。生产通用表表达式的右侧，可以在 SELECT、INSERT、UPDATE 或 DELETE 语句之前，包含序列‘(’PreparableStmt ’)’；一个 PreparableStmt 本身就是一个 SELECT、INSERT、UPDATE 或 DELETE 语句。此外，识别一元、二元和其他表达式的 a expr 和 c expr 产生式——例如 x NOT NULL、x LIKE y 以及所有算术表达式——是相互递归的。这些产生式出现在 PostgreSQL 语法的各个部分，并且是几乎所有 SQLIA 类别的语法目标，因为用户提供的输入通常对应于 a expr 右侧的产生式。 Thus, while tools using this methodology have performed well against SQLIA suites such as the AMNESIA testbed[67, 68], we question their efficacy against attacks that deliberately target the “impedance mismatch” between a generated FSA model and an underlying SQLgrammar. 因此，虽然使用这种方法的工具在对抗诸如 AMNESIA 测试平台等 SQLIA 套件方面表现良好[67,68]，但我们质疑它们在对抗故意针对生成的 FSA 模型和底层 SQLgrammar 之间的“阻抗不匹配”的攻击时的有效性。 5.1.2 验证器和数据库使用不同的语法 Many parse tree validation approaches properly represent the set of acceptable structures using a CFG, but derive their acceptable-structure set from a grammar other than that of the target database system, possibly introducing an impedance mismatch. SQLGuard[57] compares parse trees of queries assembled with and without user input, using the ZQL parser[69]; CANDID[58] uses a “standard SQL parser based on SQL ANSI 92 standard, augmented with MySQL-specific language extensions”; SQLPrevent[66] uses ANSI SQL but does not mention which version. Others only state that the grammars they use are context-free[59, 70, 71]. 许多解析树验证方法正确地使用上下文无关文法（CFG）表示可接受的结构集，但它们的可接受结构集是从目标数据库系统的语法之外的语法中派生出来的，这可能会引入阻抗不匹配。SQLGuard[57] 使用 ZQL 解析器[69]比较了带有和不带用户输入的查询的解析树；CANDID[58] 使用“基于 SQL ANSI 92 标准的标准 SQL 解析器，并增加了 MySQL 特定的语言扩展”；SQLPrevent[66] 使用 ANSI SQL，但没有提及具体版本。其他方法只说明他们使用的语法是上下文无关的[59, 70, 71]。 While it is possible to demonstrate the equivalence of two LR grammars, none of these authors have provided equivalence proofs for their implementation grammars and the SQL dialects they aim to validate. Dejector sidesteps this problem by directly using PostgreSQL’s lexer and bison grammar. Dejector’s drawback is that its implementation is coupled not only to the database distribution, but the specific parser revision; however, it prevents an attacker from constructing an input that “looks right” to the validator but yields unwanted behavior when it reaches the database. As an example, CVE-2006-2313 and CVE-2006-2314 describe a relevant vulnerability in PostgreSQL multibyte encodings[72, 73]. An attacker could craft a string that an encoding-unaware validator (i.e., one that assumes input to be in ASCII, Latin-1 or some other single-byte encoding) accepts, but which a server using a multibyte encoding (UTF-8, Shift-JIS, etc.) parses in such a way as to terminate a string literal early. We examine such parse tree differential attacks in more detail in section 6. 虽然可以证明两个 LR 语法的等价性，但这些作者都没有为他们的实现语法和他们旨在验证的 SQL 方言提供等价性证明。Dejector 通过直接使用 PostgreSQL 的词法分析器和 bison 语法来规避这个问题。Dejector 的缺点是其实现不仅与数据库分发相关联，还与特定的解析器修订版相关；然而，它防止攻击者构造一个对验证器“看起来正确”的输入，但在到达数据库时产生不想要的行为。例如，CVE-2006-2313 和 CVE-2006-2314 描述了 PostgreSQL 多字节编码中的相关漏洞[72, 73]。攻击者可以构造一个字符串，该字符串会被一个不知道编码的验证器（即假设输入为 ASCII、Latin-1 或其他单字节编码的验证器）接受，但当服务器使用多字节编码（UTF-8、Shift-JIS 等）时，会以一种方式解析该字符串，从而提前终止字符串字面量。我们在第 6 节中更详细地研究了这种解析树差异攻击。 5.2 上下文相关语言中的解析树验证 In 2006, Daniel Bleichenbacher presented an RSA signature forgery attack against PKCS #1implementations that do not correctly validate padding bytes[6]. We show that PKCS #1is context-sensitive and can be validated in the same fashion as SQL, using an attribute grammar representation[74]. 2006 年，Daniel Bleichenbacher 提出了一种针对 PKCS #1实现的RSA签名伪造攻击 ，这些实现没有正确验证填充字节[6]。我们表明，PKCS #1是上下文相关的 ，并且可以使用属性语法表示以与 SQL 相同的方式进行验证[74]。 Theorem 1 PKCS #1 is context-sensitive. Proof 1 Lemma 1 Upper bound: a linear-bounded automaton for PKCS #1 . Proof 2 Let P={wn|w is a hexadecimal octet, n is the size of the RSA modulus in bits, and wn= ’00’’01’’FF’n−len (hash)−len (d.e.)−3 ’00’ digest-encoding hash, where digest-encoding is a fixed string ∈{0, 1} as specified in RFC 2313[75] and hash is a message hash ∈{0, 1} of length appropriate for the digest-encoding}. We define a linear-bounded automaton, AP, that accepts only strings in P. The length of AP ’s tape is n, and it has states q 0, q 1,… q 67 and a reject state, qR. q 67 is the start state. Go to the leftmost cell on the tape. Consume octet 00 and transition to state q 66. If any other octet is present, transition to qR and halt. Consume octet 01 and transition to state q 65. If any other octet is present, transition to qR and halt. Consume FF octets until any other octet is observed, and transition to state q 64. (If the first octet following the 01 is anything other than FF, transition to qR and halt.) Simulate regular expression matching of the fixed digest-encoding strings (as described in the attribute grammar in the next subsection) over the next 15-19 octets as follows: (a) MD 2 sequence→ q 15 (b) MD 5 sequence→ q 15 © SHA-1 sequence→ q 19 (d) SHA-256 sequence→ q 31 (e) SHA-384 sequence→ q 47 (f) SHA-512 sequence→ q 63 (g) No match→ qR Until q 0 is reached, or the rightmost end of the tape is reached, apply the following procedure: (a) Consume an octet (b) qn→ qn−1 If in state q 0 and the tape head is at the rightmost end of the tape, Accept. Otherwise, Reject. Because P can be described by a linear-bounded automaton, it is therefore at most context-sensitive. Lemma 2 Lower bound: PKCS #1 is not context-free. Proof 3 We show that P is non-context-free using the context-free pumping lemma, which states that if L is a context-free language, any string s ∈ L of at least the pumping length p can be divided into substrings vwxyz such that|wy| 0,|wxy|≤ p, and for any i ≥ 0, vwixyiz ∈ A[10]. As stated above, n is the size of the RSA modulus in bits. (n can vary from case to case; different users will have different-sized RSA moduli, but the grammar is the same no matter the size of n.) Neither w nor y can be any of the fixed bits, ’00’, ’01’ and ’00’, since the resulting string would be too long to be in P. Nor can w or y correspond to any part of the hash, as the pumping lemma requires that w and y can be pumped an arbitrary number of times, and eventually the length of the hash alone would exceed n. Indeed, since n is fixed, the only way to pump s without obtaining a string that is either too long or too short would be if both w and y were the empty string. However, the pumping lemma requires that|wy|≥ 0, and thus P cannot be context-free. Since P is at most context-sensitive and must be stronger than context-free, P is thereforecontext-sensitive. Q.E.D. 定理 1 PKCS #1 是上下文相关的。 证明 1 引理 1 上限：PKCS #1 的线性有界自动机。 证明 2：令 P={wn|w 是一个十六进制八位字节，n 是 RSA 模数的比特大小，且 wn= ’00’’01’’FF’n−len (hash)−len (d.e.)−3 ’00’ digest-encoding hash，其中 digest-encoding 是一个固定字符串∈{0, 1}，如 RFC 2313[75]中所指定，hash 是一个消息哈希∈{0, 1}，长度适合于 digest-encoding}。我们定义一个线性有界自动机 AP，它只接受 P 中的字符串。AP 的磁带长度为 n，它具有状态 q 0，q 1，… q 67 和一个拒绝状态 qR。q 67 是起始状态。 转到磁带最左侧的单元格。 消耗八位字节 00 并转换到状态 q66。如果存在任何其他八位字节，则转换到 qR 并停止。 消耗八位元 01 并转换到状态 q65。如果存在任何其他八位元，则转换到 qR 并停止。 消耗 FF 字节，直到观察到任何其他字节，并转换到状态 q64。（如果 01 之后的第一个字节不是 FF，则转换到 qR 并停止。） 模拟固定摘要编码字符串的正则表达式匹配（如下一小节属性语法中所述）在接下来的 15-19 个八位字节上，如下所示： (a) MD2 序列→ q15 (b) MD5 序列→ q15 © SHA-1 序列→ q19 (d) SHA-256 序列→ q31 (e) SHA-384 序列→ q47 (f) SHA-512 序列→ q63 (g) 没有匹配→ qR 直到达到 q0，或者到达磁带的最右端，应用以下程序： （a）消耗一个八位字节 (b) qn→qn−1 如果在状态 q0 并且磁带头位于磁带的最右端，接受。否则，拒绝。 因为 P 可以用线性有界自动机来描述，所以它最多是上下文相关的。 引理 2 下界：PKCS #1 不是上下文无关的。 证明 3 我们使用上下文无关的泵引理来证明 P 是非上下文无关的，该引理指出如果 L 是一个上下文无关语言，那么任何长度至少为泵长度 p 的字符串 s∈Ls \\in Ls∈L 都可以被分成子串 vwxyz，使得 ∣wy∣0|wy| 0∣wy∣0，∣wxy∣≤p|wxy|≤ p∣wxy∣≤p，并且对于任何 i≥0i ≥ 0i≥0，vixyiz∈Av^i xy^iz \\in Avixyiz∈A[10]。 如上所述，n 是 RSA 模数的位数。（n 可以因情况而异；不同的用户将有不同的大小的 RSA 模数，但语法是相同的，无论 n 的大小如何。）w 和 y 都不能是固定的位‘00’、‘01’和‘00’，因为结果字符串会太长而不在 P 中。w 或 y 也不能对应哈希的任何部分，因为泵引理要求 w 和 y 可以被任意次数地泵送，最终哈希的长度本身会超过 n。实际上，由于 n 是固定的，唯一在不获得过长或过短的字符串的情况下泵送 s 的方法是如果 w 和 y 都是空字符串。然而，泵引理要求 ∣wy∣≥0|wy|≥ 0∣wy∣≥0，因此 P 不能是上下文无关的。 由于 P 最多是上下文相关的，并且必须比上下文无关更强，因此 P 是上下文相关的。证毕。 5.2.1 PKCS #1 的属性文法 The following attribute grammar, where (T) represents any valid octet from 00 to FF, generates strings in P for arbitrary n: (S)::= 00 01 (FFs) 00 (ASN. 1) Valid ((S))← Valid ((ASN. 1)) Len ((FFs))= n- Len ((ASN. 1))- 3 (FFs)::= FF FF FF FF FF FF FF FF Len ((FFs))← 8|(FFs) 2 FF Len ((FFs))←(Len ((FFs) 2)+ 1) (ASN. 1)::= (Digest-Algo) (Hash) Valid ((ASN. 1))←(HashLen ((Digest-Algo))= Len ((Hash))) Len ((ASN. 1))←(Len ((Digest-Algo))+ Len ((Hash))) (Digest-Algo)::= (MD2) HashLen ((Digest-Algo))← HashLen ((MD2)) The following attribute grammar, where (T) represents any valid octet from 00 to FF, generates strings in P for arbitrary n: (S)::= 00 01 (FFs) 00 (ASN. 1) Valid ((S))← Valid ((ASN. 1)) Len ((FFs))= n- Len ((ASN. 1))- 3 (FFs)::= FF FF FF FF FF FF FF FF Len ((FFs))← 8|(FFs) 2 FF Len ((FFs))←(Len ((FFs) 2)+ 1) (ASN. 1)::= (Digest-Algo) (Hash) Valid ((ASN. 1))←(HashLen ((Digest-Algo))= Len ((Hash))) Len ((ASN. 1))←(Len ((Digest-Algo))+ Len ((Hash))) (Digest-Algo)::= (MD2) HashLen ((Digest-Algo))← HashLen ((MD2)) 以下属性文法，其中（T）表示从 00 到 FF 的任何有效八位字节，为任意 n 生成 P 中的字符串： (S) ::= 00 01 (FFs) 00 (ASN. 1) 有效 ((S)) ← 有效 ((ASN. 1)) 长度 ((FFs)) = n - 长度 ((ASN. 1)) - 3 (FFs) ::= FF FF FF FF FF FF FF FF Len ((FFs))← 8|(FFs) 2 FF Len ((FFs))←(Len ((FFs) 2)+ 1) (ASN. 1) ::= (摘要算法) (哈希) 有效 ((ASN. 1))←(哈希长度 ((摘要算法))= 哈希长度) Len ((ASN. 1))←(Len ((Digest-Algo))+ Len ((Hash))) （摘要算法） ::= （MD2） HashLen ((摘要算法))← HashLen ((MD2)) 第 16 页 Len ((摘要算法))← 18 HashLen ((摘要算法))← HashLen ((MD5)) Len ((摘要算法))← 18 |(SHA-1) HashLen ((摘要算法))← HashLen ((SHA-1)) Len ((摘要算法))← 15 |(SHA-256) HashLen ((摘要算法))← HashLen ((SHA-256)) Len ((摘要算法))← 19 |(SHA-384) HashLen ((摘要算法))← HashLen ((SHA-384)) Len ((摘要算法))← 19 |(SHA-512) HashLen ((摘要算法))← HashLen ((SHA-512)) Len ((摘要算法))← 19 (MD2)::= 30 20 30 0C 06 08 2A 86 48 86 F7 0D 02 02 05 00 04 10HashLen ((MD2))← 16 (MD5)::= 30 20 30 0C 06 08 2A 86 48 86 F7 0D 02 05 05 00 04 10 HashLen ((MD5))← 16 (SHA-1) ::= 30 21 30 09 06 05 2B 0E 03 02 1A 05 00 04 14HashLen ((SHA-1)) ← 20 (SHA-256)::= 30 31 30 0D 06 09 60 86 48 01 65 03 04 02 01 05 00 04 20HashLen ((SHA-256))← 32 (SHA-384) ::= 30 41 30 0D 06 09 60 86 48 01 65 03 04 02 02 05 00 04 30HashLen ((SHA-384)) ← 48 (SHA-512) ::= 30 51 30 0D 06 09 60 86 48 01 65 03 04 02 03 05 00 04 40 HashLen ((SHA-512))← 64 （哈希）::= （T）16 Len ((Hash))← |16 Len ((Hash))← Len ((Hash) 2)+ 1 6 解析树差异分析 We observe that, while different implementations of the same specification should process input and perform tasks in effectively the same way as each other, it is often the case that different implementations parse inputs to the program (or messages passed internally) differently depending on how the specification was interpreted or implemented. Such im-plementations provide distinct dialects of a protocol. While these dialects may be mutually intelligible for the purpose of non-malicious information exchange, prior security assump-tions may fail. In order to retain the security properties of each process in an environment where several processes participate in sequentialized communication, one must show that the properties also hold for the concurrent system they constitute. 我们观察到，尽管同一规范的不同实现应该以相同的方式处理输入和执行任务，但通常情况下，不同的实现会根据规范的解释或实现方式不同而对程序的输入（或内部传递的消息）进行不同的解析。这样的实现提供了协议的不同方言。虽然这些方言可能在非恶意信息交换的目的上是相互可理解的，但先前的安全假设可能会失效。为了在多个进程参与顺序化通信的环境中保留每个进程的安全属性，必须证明这些属性也适用于它们构成的并发系统。 We have developed a powerful technique to enhance code auditing and protocol analysis, known as the parse tree differential attack[8], wherein we give two different implementa-tions of the same specification identical state and input parameters, consider their decodings as concrete parse trees, and enumerate the differences between the trees. Deviations be-tween the trees indicate potential problems, e.g. an area of implementor discretion due to specification ambiguity or an implementation mistake. 我们开发了一种强大的技术来增强代码审计和协议分析，称为解析树差异攻击[8]。在此技术中，我们对同一规范的两种不同实现给予相同的状态和输入参数，将它们的解码视为具体的解析树，并列举出这些树之间的差异。树之间的偏差表明可能存在潜在问题，例如由于规范模糊导致的实施者自由裁量权或实施错误。 Looking back to the work of Shannon et al. (Section 3.2), the goal of a parse tree differential attack is to find combinations of MsrcM_{src}Msrc​, Esrc\\mathcal{E}_{src}Esrc​, and Ddst\\mathcal{D}_{dst}Ddst​ such that M≠D(E(M))M eq \\mathcal{D}(\\mathcal{E}(M))M=D(E(M)), with MMM semantically valid for the source and D(E(M))\\mathcal{D}(\\mathcal{E}(M))D(E(M)) semantically valid for the destination, where the destination’s response to D(E(M))\\mathcal{D}(\\mathcal{E}(M))D(E(M)) includes computations that its response to MMM would not have. The set: {MA∪MB∣MA≠DB(EA(MA)),MB≠DA(EB(MB))}\\{M_A\\cup M_B\\mid M_A eq\\mathcal{D}_B (\\mathcal{E}_A (M_A)), M_B eq\\mathcal{D}_A (\\mathcal{E}_B (M_B))\\}{MA​∪MB​∣MA​=DB​(EA​(MA​)),MB​=DA​(EB​(MB​))} describes a lower bound on the set of vulnerabilities present on the attack surface of the composed system that has implementations (i.e., processes) A and B as endpoints of a common channel (after Howard et al[76]). 回顾 Shannon 等人的工作（第 3.2 节），解析树差异攻击的目标是找到 Msrc、Esrc 和 Ddst 的组合，使得 M≠D(E(M))M eq D (E (M))M=D(E(M))，其中 M 在语义上对源有效，而 D(E(M))D (E (M))D(E(M)) 在语义上对目标有效，且目标对 D(E(M))D (E (M))D(E(M)) 的响应包括其对 M 的响应所包含的计算。 {MA∪MB∣MA≠DB(EA(MA)),MB≠DA(EB(MB))}\\{M_A\\cup M_B\\mid M_A eq\\mathcal{D}_B (\\mathcal{E}_A (M_A)), M_B eq\\mathcal{D}_A (\\mathcal{E}_B (M_B))\\} {MA​∪MB​∣MA​=DB​(EA​(MA​)),MB​=DA​(EB​(MB​))} 上述公式描述了由实现（即进程）A 和 B 作为公共通道端点的组合系统攻击面上存在的漏洞集的下限（根据 Howard 等人[76]）。 6.1 攻击面发现 We have used edge-cases identified by parse tree differential analysis to isolate serious vul-nerabilities in X.509. We found many instances where two implementations of the X.509system behaved differently when given the same input, in such a way that these differences led to a certificate authority signing a certificate that it viewed as being granted one privi-lege, while the client-side application (the web browser) parsed the same input in a manner yielding different security assertions, leading to a compromise of the system[8]. 我们使用了通过解析树差异分析确定的边缘情况来隔离X.509 中的严重漏洞。我们发现许多情况下，两个X.509 系统的实现对相同的输入表现出不同的行为，这些差异导致证书颁发机构签署了一个它认为被授予一种特权的证书，而客户端应用程序（即网络浏览器）以不同的方式解析相同的输入，产生不同的安全断言，从而导致系统被破坏[8]。 Example 5 (Null terminator attack) The attacker presents a certificate signing request to a certificate authority (CA) that will read the Common Name as www.paypal.com\\x00.badguy.com and return a signed certificate for this Subject CN. The message that this certificate repre-sents is M, and the certificate itself is E (M). Now present E (M)) to a browser vulnerable to the null terminator attack. Although the CN field’s value in M is www.paypal.com\\x00.badguy.com, its value in D (E (M)) is www.paypal.com. 示例 5（空终止符攻击）：攻击者向证书颁发机构（CA）提交一个证书签名请求，该请求将把通用名称读作www.paypal.com\\x00.badguy.com，并返回一个针对此主题 CN 的已签名证书。这个证书所代表的消息是 M，而证书本身是 E (M)。现在将 E (M) 呈现给易受空终止符攻击影响的浏览器。尽管在 M 中的 CN 字段值是www.paypal.com\\x00.badguy.com，但在 D (E (M)) 中的值却是www.paypal.com。 In this case, the decoder at the CA correctly interprets the CN as a Pascal-style string (which can include the\\x00 character), compares its reading of the CN with the credentialspresented by the source, and responds with an encoding of a message incorporating this valid-but-peculiar CN. Little does the destination know, other destinations’ decoders interpret theCN as a C-style string, for which\\x00 is an end-of-string indicator, and decode the CA’sencoding into a signed message vouching that the certificate is valid for www.paypal.com! 在这种情况下，CA 的解码器正确地将 CN 解释为 Pascal 风格的字符串（可以包含\\x00 字符），将其对 CN 的读取与源提供的凭据进行比较，并响应一个包含这个有效但特殊的 CN 的消息编码。目的地并不知道，其他目的地的解码器将 CN 解释为 C 风格的字符串，其中\\x00 是字符串结束的指示符，并将 CA 的编码解码为一个签名消息，证明该证书对www.paypal.com有效！ 6.2 解析树差异的其他应用 In certain settings, aspects of protocol implementation divergence are of particular sensi-tivity; a prime example is anonymity systems. Prior work has shown that the anonymityprovided by a lower-layer tool can be compromised if higher-layer differences are revealed toan attacker; the EFF’s Panopticlick tool demonstrates how to use web browser identifiers towhittle away the assurances offered by low-level anonymity systems such as Tor[77]. Thepotential for an attacker to perform parse tree differential analysis of common client ap-plication implementations of standard protocols a priori allows her to generate a codebookof sorts, consisting of the inputs which, when sent to the unsuspecting user, will triggerthe user’s client (web browser, etc.) to respond in a way that will enable the attacker topartition the anonymity set[78]. Similarly, the use of a parse tree differential analysis toolmay enhance other fingerprinting-based attacks. 在某些情况下，协议实现差异的某些方面特别敏感；一个典型的例子是匿名系统。先前的研究表明，如果高层差异被攻击者发现，低层工具提供的匿名性可能会被破坏；EFF 的 Panopticlick 工具展示了如何使用网络浏览器标识符来削弱低级匿名系统（如 Tor）所提供的保证[77]。攻击者可以对标准协议的常见客户端应用程序实现进行解析树差异分析，从而生成一种代码手册，其中包含输入，当这些输入发送给毫无戒心的用户时，将触发用户的客户端（如网络浏览器等）以某种方式响应，使攻击者能够划分匿名集[78]。同样，使用解析树差异分析工具可能增强其他基于指纹的攻击。 A more indirect means of using parse tree differentials as oracles appears in Clayton’swork on British Telecom’s CleanFeed anti-pornography system[79]. He constructed TCP packets with a specially chosen TTL value which, if actually used, would leverage the Clean-Feed proxy system’s traffic-redirection behavior against the behavior of non-interdicted traf-fic so as to selectively reveal exactly which IP addresses hosted material that BT was at-tempting to block! 在克莱顿有关英国电信的“净源”反色情系统的研究中[79]，出现了利用解析树差异作为“神谕”的一种更为间接的方法。他构造了具有特定选择的生存时间（TTL）值的 TCP 数据包，如果实际使用，将利用“净源”代理系统的流量重定向行为与未被拦截的流量行为之间的差异，从而有选择地揭示出英国电信试图屏蔽的材料究竟存放在哪些 IP 地址上！ Notably, Clayton’s attack makes use of three separate protocols — TCP, IP, and ICMP— being used by multiple systems (a user’s, BT’s, and that of a banned site). This highlights the empirically well-known observation that composed systems tend to have characteristic behaviors that result from composition and are not obviously inherent in the individual components. In critical applications (such as an anonymity system used to evade violent repression), such behaviors can be deadly. To quote a hacker maxim, “Composition Kills”. 值得注意的是，克莱顿的攻击利用了三个独立的协议——TCP、IP 和 ICMP——被多个系统（用户的、BT 的以及被禁止的网站的）使用。这突显了一个经验上众所周知的观察结果，即组合系统往往具有由组合产生的特征行为，这些行为在单个组件中并不明显存在。在关键应用（例如用于逃避暴力镇压的匿名系统）中，这种行为可能是致命的。引用一句黑客格言，“组合是致命的”。 6.2.1 一个明确的解析树微分排序 Consider a parse tree differential attack executed between two different implementations of the same protocol a “zeroth-order” parse tree differential. It has two steps, protocol encoding and protocol decoding. Now consider a parse tree differential attack executed between two different implemen-tations of two different protocols, e.g. ASN. 1 → HTTP. (e.g., X generates ASN. 1 which is transformed into HTTP which is parsed by Y). The transformation between one proto-col and another is a point of interest; can, for instance, malformed ASN. 1 be generated with respect to the transformation function to HTTP such that Y performs some unex-pected computation? This is a first-order parse tree differential. It has three steps: protocol encoding, protocol transformation (to protocol’) and protocol’ decoding. The construction extends recursively. 将针对同一协议的两种不同实现所执行的解析树差异攻击视为“零阶”解析树差异攻击。它包含两个步骤，即协议编码和协议解码。 现在考虑在两个不同协议的两种不同实现之间执行的解析树差异攻击，例如 ASN. 1 到 HTTP（例如，X 生成 ASN. 1，其被转换为 HTTP 并由 Y 进行解析）。一种协议到另一种协议的转换是一个关注点；例如，能否生成针对转换为 HTTP 的转换函数的畸形 ASN. 1，从而使 Y 执行一些意外的计算？这是一个一阶解析树差异。它有三个步骤：协议编码、协议转换（到协议’）和协议’解码。 这种构造是递归扩展的。 7 为什么约翰尼无法检测 One arguably non-principled but practically common form of composition is that of adding an intrusion detection/prevention system (IDS) to a target known to be susceptible to exploitation. The IDS monitors the target’s inputs and/or state, models the target’s com-putation, and is expected to catch the exploits. This design obviously relies on the ability of the IDS to match at least those aspects of the target’s input processing that serve as attack vectors; without such matching the IDS does not reduce insecurity, and may in fact increase it by adding exploitable bugs of its own. Far from being merely theoretical, the latter is a hard reality well-known to security practitioners on both the attack and defense sides (see, e.g.,[80]). 一种或许缺乏原则性但又在实际中颇为常见的编写方式是：在已知容易遭受攻击的系统上添加入侵检测/预防系统（IDS）。该系统会监控目标的输入和/或状态，模拟目标的计算过程，并期望能够发现攻击行为。这种设计显然依赖于 IDS 能够至少匹配目标输入处理中作为攻击途径的那些方面；如果没有这种匹配，IDS 并不能降低安全风险，反而可能会因自身引入可利用的漏洞而增加风险。这种做法绝非仅仅是理论上的设想，而是攻击方和防御方都熟知的现实情况（例如，参见[80]）。 The language-theoretic and computational magnitude of the challenge involved in con-structing such an effective matching in this de-facto composed design should by now be clear to the reader, as it requires approaching de-facto computational equivalence between the IDS and the target input handling units. The first work[81] to comprehensively demonstrate the fundamental weakness of network intrusion detection systems (NIDS) was, predictably, based on hacker intuitions. These intuitions were likely informed by previous use of TCP/IP stack implementation differences for system fingerprinting in tools like Nmap, Xprobe, and Hping2 (e.g.,[82] methodically explores the differences in OS network stacks’ response to various ICMP features). Subsequent research established that the only hope of addressing this weakness was precise matching of each target’s session (re) assembly logic by the NIDS (e.g.,[83, 84, 85]). 在这种实际构建的设计中，构建这样一个有效的匹配所涉及的语言理论和计算难度，想必读者现在已经很清楚了，因为这需要实现入侵检测系统（IDS）与目标输入处理单元之间的实际计算等效性。第一篇全面展示网络入侵检测系统（NIDS）根本缺陷的研究[81]，显然是基于黑客的直觉得出的结论。这些直觉很可能受到了像 Nmap、Xprobe 和 Hping2 等工具中使用 TCP/IP 栈实现差异进行系统指纹识别的先前应用的影响（例如，[82] 方法系统地探讨了操作系统网络栈对各种 ICMP 特性的响应差异）。后续的研究表明，解决这一缺陷的唯一希望在于入侵检测系统能够精确匹配每个目标的会话（重新）组装逻辑（例如，[83， 84， 85]）。 In host-based intrusion detection systems (HIPS), the problem of matching the “de-fending” computation with the targeted computation is no less pronounced. For example, Garfinkel[86] enumerates a number of traps and pitfalls of implementing a system call-monitoring reference monitor and warns that “Duplicating OS functionality/code should be avoided at all costs.” We note that isolating the reference monitor logic from the rest of the system would seem advantageous were it possible to validate the matching between the system’s own computation and the isolated, duplicated computation; however, as we have seen, such validation coule easily be undecidable. 在基于主机的入侵检测系统（HIPS）中，将“防御”计算与目标计算相匹配的问题同样突出。例如，加尔芬克尔[86]列举了实现系统调用监控参考监视器时的一些陷阱和隐患，并警告说“应不惜一切代价避免复制操作系统的功能/代码”。我们注意到，如果能够验证系统自身的计算与隔离后的重复计算之间的匹配情况，将参考监视器逻辑与系统其余部分隔离开来似乎是有利的；然而，正如我们所看到的，这种验证很容易变得不可判定。 In a word, hardening a weak system by composing it with a monitor that replicates the computation known or suspected to be vulnerable likely attempts to convert an input-validation kind of undecidable problem into a computational-equivalence undecidable prob-lem – hardly an improvement in the long run, even though initially it might appear to gain some ground against well-known exploits. However, it leaves intact the core cause of the target’s insecurity, and should not therefore be considered a viable solution. 总之，通过将一个脆弱的系统与一个能够模拟已知或疑似存在漏洞的计算过程的监控器相结合，实际上是试图将一种输入验证类的不可判定问题转化为一种计算等价类的不可判定问题——从长远来看，这绝非一种改进，尽管在初始阶段它可能在对抗已知漏洞方面取得了一定进展。然而，这种方法并未消除目标系统不安全的根本原因，因此不应被视为一种可行的解决方案。 One common approach for modeling program behavior involves sequences of system calls[87, 88]. Because system calls represent the method by which processes affect the external world, these sequences are thought to provide the most tangible notion of system behavior. Despite their apparent success in detecting anomalies due to attacks, such models have several shortcomings, including susceptibility to mimicry attacks[89]; an attacker can keep the system within some epsilon of the “normal” patterns while executing calls of their choosing. This problem suggests that we should investigate the extraction and use of a more fine-grained notion of program activity. Note that our goal is not to criticize system call approaches for being susceptible to mimicry attacks; instead, the lesson we should learn is that relatively large amounts of work can happen “between” system calls, and it is the more precise nature of this activity that can help inform models of program behavior. 一种常见的用于描述程序行为的建模方法是通过一系列系统调用来实现的[87, 88]。因为系统调用代表了进程影响外部世界的方式，所以这些序列被认为能提供关于系统行为最直观的概念。尽管这些模型在检测由攻击引起的异常方面表现出明显的成效，但它们也有几个缺点，包括容易受到模仿攻击的影响[89]；攻击者可以在执行他们选择的调用操作的同时将系统保持在“正常”模式的某个误差范围内。这个问题表明，我们应该研究提取和使用更精细的程序活动概念。请注意，我们的目标并非批评系统调用方法容易受到模仿攻击的影响；相反，我们应该吸取的教训是，大量的工作可以在系统调用之间发生，并且正是这种活动的更精确性质能够帮助为程序行为模型提供信息。 Popular flavors of model or anomaly-based intrusion detection often offer only very slight deltas from each other; Taylor and Gates[90] supply a good critique of current approaches, and a recent paper by Sommer and Paxson also explores the reasons why we as a community might not successfully use machine learning for intrusion detection[91]. The prevailing approach to detection (matching sequences of system calls) is a glorified form of the oft-critized regular expression string matching used in misuse signature-based systems like Snort and Bro. 基于模型或异常的入侵检测的常见类型往往彼此之间的差异非常小；泰勒和盖茨[90]对当前的方法进行了很好的批评，并且索默和帕克斯森最近的一篇论文也探讨了我们这个社区为何可能无法成功地将机器学习应用于入侵检测的原因[91]。入侵检测的主流方法（匹配系统调用序列）是一种对经常受到批评的正则表达式字符串匹配形式的美化，这种匹配形式在像 Snort 和 Bro 这样的误用特征签名系统中被使用。 An impressive number of RAID, CCS, and Oakland papers have spilled a lot of digital ink offering slight twists or improvements on the original system call sequence model proposed by Denning and matured by Forrest, Somayaji et al.[92, 87, 93]. This follow-on pack of work considers, in turn, changes that include: longer sequences, sequences with more context information (e.g., instruction pointer at time of call, arguments, machine CPU register state, sets of open files and resources), anomalous system call arguments, cross-validation of system call sequences across operating systems, and other various insignificant changes in what information is examined as the basis of a model. 大量的《RAID》、《CCS》和《Oakland》相关论文大量使用数字语言，对最初由丹宁提出的系统调用序列模型进行了细微的调整或改进，并由福雷斯特、索马亚吉等人进一步完善[92， 87， 93]。这一后续系列的研究依次探讨了以下变化：更长的序列、包含更多上下文信息的序列（例如，调用时的指令指针、参数、机器 CPU 状态、打开的文件集和资源集合）、异常的系统调用参数、不同操作系统之间系统调用序列的交叉验证，以及在作为模型基础所考察的信息方面的一些其他微不足道的变化。 The most natural next step was to attempt to characterize normal behavior, abnormalbehavior, and malware behavior using control-flow graph structures. From this perspective, sequences of system calls are very simple “graphs” with a linear relationship. 接下来最自然的步骤就是尝试利用控制流图结构来描述正常行为、异常行为以及恶意软件行为。从这个角度来看，系统调用序列就是非常简单的“图”，并且具有线性关系。 Unfortunately, this move toward more complicated models of representing execution behavior reveal just how limited we are in our expected success. When viewed from the pattern of language-theoretic equivalence, this style of intrusion detection is essentially a problem of matching grammars, and it suffers from the same limitations as proving that two protocol implementations of sufficient complexity actually accept the same strings. 不幸的是，这种朝着更复杂的执行行为表示模型的转变，揭示了我们在预期的成功方面是多么的有限。从语言理论等价性的模式来看，这种入侵检测风格本质上是一个语法匹配的问题，它与证明两个足够复杂的协议实现实际上能接受相同的字符串所面临的限制是相同的。 The intrusion detection community overlooks this critically important point in its search for ever more efficient or representative models of malicious (or benign) behavior. Adding incremental adornments to a language model will not result in a dramatic advancement of our ability to detect malicious computation; it can only serve to increase the complexity of the language – and hence increase the difficulty of showing that the particular model accepts some precise notion of malicious or abnormal. This is a counter-intuitive result: initiatives aimed at “improving” the power of an IDS model actually detract from its ability to reliably recognize equivalent behavior. In this case, “more powerful” maps to “less reliable.” 入侵检测领域的研究者们在追求更高效或更具代表性的恶意（或良性）行为模型的过程中，忽略了这一至关重要的要点。仅仅对语言模型进行逐步的修饰，并不会显著提升我们检测恶意计算的能力；反而只会增加语言的复杂性——从而加大证明特定模型能够接受某种精确的恶意或异常概念的难度。这是一个出人意料的结果：旨在“增强”入侵检测系统模型能力的举措实际上却削弱了其可靠识别相同行为的能力。在这种情况下，“更强大”意味着“更不可靠”。 We note that, to the best of our knowledge, Schneider[94] comes closest to considering the limits of security policy enforceability as a computation-theoretic and formal language-theoretic phenomenon, by matching desired policy goals such as bounded memory or real-time availability to classes of automata capable of guaranteeing the acceptance or rejection of the respective strings of events. In particular, Bu¨chi automata are introduced as a class of security automata that can terminate insecure executions defined by the Lamport’s safety property: execution traces excluded from the policy can be characterized as having a (finite) set of bad prefixes (i.e., no execution with a bad trace prefix is deemed to be safe). 我们注意到，据我们所知，施耐德[94]的观点最接近将安全策略的可执行性限制视为一种计算理论和形式语言理论现象。他将诸如有限内存或实时可用性等预期的策略目标与能够确保相应事件字符串被接受或拒绝的各类自动机相匹配。特别地，布奇自动机被引入作为一种安全自动机类，它可以终止由拉姆波特的安全属性定义的不安全执行：被政策排除在外的执行轨迹可以被描述为具有（有限）不良前缀集（即，任何具有不良轨迹前缀的执行都不被视为安全的）。 Schneider’s approach connects enforceable security policies with the language-theoretic properties of the system’s language of event traces. We note that the next step is to consider this language is an input language to the automaton implementing the policy mechanism, and to frame its enforcement capabilities as a language recognition problem for such trace languages. 施奈德的方法将可执行的安全策略与系统事件跟踪语言的语义理论特性联系起来。我们注意到接下来的步骤是将这种语言视为实现策略机制的自动机的输入语言，并将其执行能力表述为针对此类跟踪语言的语义识别问题。 8 未来的工作 In an expanded version of this paper, we will show how context-free parse tree validation can be extended to the context-sensitive languages, using attribute grammars[74] as both a representational formalism and a code-generation tool[95]. Our future work will integrate existing work on generation of verifiable, guaranteed-terminating parsers[16, 17, 18] with verification of finite-state concurrent systems and the work of Bhargavan et al[96] on the use of refinement types to carry security invariants (and, by extension, input-language preconditions) in order to develop a complete verified network stack that is compositionally correct from end to end. We also plan to build on previous work in automated implementation checking, such as aspier[97], to develop automated parse tree differential analysis tools (akin to smart fuzzers) for the benefit of security auditors. 在本文的扩展版本中，我们将展示如何将无上下文的解析树验证扩展到有上下文的语言中，使用属性语法[74]作为一种表示形式的规范以及一种代码生成工具[95]。 我们未来的研究将把现有的关于生成可验证、保证终止的解析器[16， 17， 18]的工作与有限状态并发系统的验证以及巴尔加万等人[96]关于使用细化类型来承载安全不变量（以及由此扩展的输入语言前置条件）以开发一个完整的经过验证的网络栈（从头到尾都是组合正确性的）的工作结合起来。我们还计划在自动实现检查方面利用先前的工作，例如 aspier[97]，以开发用于安全审计员的自动解析树差异分析工具（类似于智能模糊器）。 We posit that by treating valid or expected inputs to programs and network protocol stacks as input languages that must be simple to parse we can immensely improve security. We posit that the opposite is also true: a system whose valid or expected inputs cannot be simply parsed cannot in practice be made secure. 第二部分：安全设计的语言理论设计 9 关于安全的语言理论观点概述 我们假设将程序和网络协议栈所接受的有效或预期的输入视为必须易于解析的输入语言，这样就能极大地提高安全性。我们还提出相反的观点：如果一个系统的有效或预期输入无法轻易解析，那么实际上就无法实现安全。 Indeed, a system’s security is largely defined by what computations can and cannot occur in it under all possible inputs. The parts of a system where input-driven computation occurs are typically meant to act together as a recognizer for the inputs’ validity, i.e., they are expected to accept valid or expected inputs, 9 and reject bad inputs. Exploitation — an unexpected input-driven computation — usually occurs there as well; thinking of it as an input language recognizer bug often helps find exploitable vulnerabilities. 事实上，一个系统的安全性很大程度上取决于在所有可能的输入条件下，该系统中哪些计算能够进行、哪些不能进行。系统中那些由输入驱动的计算部分通常被期望作为一个输入有效性的识别器共同发挥作用，即它们应接受有效或预期的输入，而拒绝不良输入。意外的输入驱动计算（即利用）通常也会出现在这些部分；将它视为输入语言识别器的缺陷，往往有助于发现可利用的漏洞。 Crucially, for complex inputs (input languages), the recognizer that matches the pro-grammer’s expectations can be equivalent to the Halting Problem, that is, undecidable. Then no generic algorithm to establish the inputs’ validity is possible, no matter how much effort is put into making the input data “safe”. In such situations, whatever actual checks the software performs on its inputs at various points are unlikely to correspond to the pro-grammer assumptions of validity or safety at these points or after them. This greatly raises the likelihood of exploitable input handling errors. 至关重要的是，对于复杂的输入（输入语言），能够符合程序员预期的识别器可能等同于“停机问题”，即无法解决的难题。这样一来，无论投入多少精力来确保输入数据的安全性，都无法找到通用算法来验证输入的有效性。在这种情况下，软件在不同阶段对输入进行的任何实际检查都不太可能符合这些阶段或之后的程序员对于有效性和安全性的假设。这大大增加了可能出现可利用的输入处理错误的可能性。 Furthermore, most approaches to input validation employ hand-written recognizers, rather than recognizers generated from a protocol’s grammar even if such a formal gram-mar is available. These ad-hoc recognizers at most using regular expressions to whitelist acceptable inputs and/or blacklist potentially-malicious ones. Such recognizers, however, are powerless to validate stronger classes of languages that allow for recursively nested data structures, such as context-free languages, which require more powerful recognizers. 此外，大多数输入验证方法都采用手工编写的识别器，而非基于协议语法生成的识别器（即便存在这样的正式语法）。这些临时编写的识别器最多只是使用正则表达式来白名单可接受的输入和/或黑名单潜在的恶意输入。然而，这些识别器无法验证更高级别的语言类别，例如允许递归嵌套数据结构的上下文无关语言，因为这类语言需要更强大的识别器。 A protocol that appears to frustratingly resist efforts to implement it securely, to weed out vulnerabilities by comprehensively testing its implementations, or to watch it effectively with an IDS behaves that way, we argue, because its very design puts programmers in the position of unwittingly trying to solve (or approximate a solution to) undecidable problems. Of course, for such problems no “80/20” engineering approximation is possible. 我们认为，这种协议之所以会出现这种令人沮丧的状况，是因为其设计本身就使得程序员在不知不觉中陷入了试图解决（或近似解决）不可解问题的境地。当然，对于这类问题，不存在“80/20”式的工程简化方法。 Conversely, as Sassaman and Patterson have shown, understanding the flavor of mis-match between the expected and the required (or impossible) recognizer power for the pro-tocol as an input language to a program considerably eases the task of vulnerability hunting and exploit construction, as it helps to find false data and state validity assumptions that open ways to manipulate the target program’s state. 相反，正如萨萨曼和帕特森所指出的那样，将协议作为程序的输入语言时，理解预期与实际（或不可能达到的）识别器能力之间的差异所带来的不匹配的特征，会极大地简化漏洞检测和漏洞利用构建的工作，因为它有助于发现错误的数据和状态有效性假设，从而为操纵目标程序的状态开辟了途径。 Recognizers and “weird machines”. The latter observation perfectly agrees with the modern understanding of exploit programming as “setting up, instantiating, and program-ming a weird machine”[98, 99]. The term “weird machine” refers to the computational environment (embedded in the target system) that consists of a subset of the actually pos-sible system states (as opposed to valid states envisioned by designers and programmers), which, as Dullien has observed, explodes in the presence of errors and bugs, and of transi-tions between them caused by crafted inputs. In a word, malicious computation constructed by the attacker runs on the “weird machine” inside the target. 识别器与“奇异机器”。后一种观察结果与现代对漏洞利用编程的理解完全一致，即“设置、实例化并编程一个奇异机器”[98, 99]。术语“奇异机器”指的是嵌入在目标系统中的计算环境（由实际可能的系统状态（而非设计者和程序员所设想的合法状态）组成），正如杜利恩所指出的，在存在错误和漏洞以及由精心设计的输入导致的相互转换的情况下，这种环境会变得异常复杂。总之，攻击者构建的恶意计算是在目标系统内部的“奇异机器”上运行的。 Thus programming an exploit involves enumerating the relevant unanticipated system states and transitions (cf. the axiomatic definition of vulnerability by Bishop et al.[100] in terms of unauthorized system states and transitions). Failures of input recognition, and in particular false assumptions regarding data received as input provide a rich source of such states and transitions. 因此，编写漏洞利用程序需要列出所有可能的意外系统状态和转换（参考比西普等人[100]从未授权系统状态和转换的角度给出的漏洞的公理定义）。输入识别的失败，尤其是对作为输入接收的数据的错误假设，为这类状态和转换提供了丰富的来源。 10 语言层面的安全设计原则 Decidability matters. Formally speaking, a correct protocol implementation is defined by the decision problem of whether the byte string received by the stack’s input handling units is a member of the protocol’s language. This problem has two components: first, whether the input is syntactically valid according to the grammar that specifies the protocol, and second, whether the input, once recognized, generates a valid state transition in the state machine that represents the logic of the protocol. The first component corresponds to the parser and the second to the remainder of the implementation. 可判定性至关重要。从形式上讲，一个正确的协议实现是由这样一个决策问题来定义的：输入处理单元接收到的字节字符串是否属于该协议的语言。这个问题包含两个部分：首先，根据规定该协议的语法，输入是否在语法上是有效的；其次，一旦识别出输入，它是否会在代表该协议逻辑的状态机中产生一个有效的状态转换。第一个部分对应于解析器，第二个部分则对应于实现的其余部分。 The difficulty of this problem is directly defined by the class of languages to which the protocol belongs. Good protocol designers don’t let their protocols grow up to be Turing-complete, because then the decision problem is Undecidable. 这个问题的难易程度直接取决于该协议所属的语言类别。优秀的协议设计者不会让他们的协议发展成为图灵完备的系统，因为那样的话，决策问题就会变得不可判定。 In practice, undecidability suggests that no amount of programmer or QA effort is likelyto expose a comprehensive selection of the protocol’s exploitable vulnerabilities related toincorrect input data validity assumptions. Indeed, if no generic algorithm to establish inputvalidity is possible, then whatever actual validity checks the software performs on its inputsat various points are unlikely to correspond to the programmer assumptions of such validity. Inasmuch as the target’s potential vulnerability set is created by such incorrect assumptions, it is likely to be large and non-trivial to explore and prune. 实际上，不可判定性表明，无论程序员或质量保证人员付出多大努力，都不太可能发现该协议中与不正确输入数据有效性假设相关的所有可利用漏洞。事实上，如果不存在能够确定输入有效性的通用算法，那么软件在不同环节对输入所进行的任何实际有效性检查都不太可能符合程序员对这种有效性的假设。由于目标的潜在漏洞集是由这些不正确的假设所形成的，因此要探索和剔除这些漏洞很可能是庞大且复杂的。 From malicious computation as the basis of the threat model and the language-theoretic understanding of inputs as languages, several bedrock security principles follow: 基于恶意计算作为威胁模型的基础，并从语言理论的角度对输入进行理解，由此衍生出了若干基本的安全原则： Principle 1: “Starve the Turing beast”, request and grant minimal computational power. Computational power is an important and heretofore neglected dimension of the attack surface. Avoid exposing unnecessary computational power to the attacker. An input language should only be as computationally complex as absolutely needed, so that the computational power of the parser necessary for it can be minimized. For example, if recursive data structures are not needed, they should not be specified in the input language. The parser should be no more computationally powerful than it needs to be. For exam-ple, if the input language is deterministic context-free, then the parser should be no morepowerful than a deterministic pushdown automaton. For Internet engineers, this principle can be expressed as follows: • a parser must not provide more than the minimal computational strength necessary to interpret the protocol it is intended to parse, and • protocols should be designed to require the computationally weakest parser necessary to achieve the intended operation. An implementation of a protocol that exceeds the computational requirements for parsingthat protocol’s inputs should be considered broken. Protocol designers should design their protocols to be as weak as possible. Any increase in computational strength of an input language should be regarded as a grant of additional privilege, and thus increasing security risks. Such increases should therefore be entered into reluctantly, with eyes open, and should be considered as part of a formal risk assessment. In the very least, designers should be guided by the Chomsky hierarchy (described in the sidebar). Input-handling parts of most programs are essentially Turing machines, whether this level of computational power is needed or not. From the previously discussed malicious computation perspective of exploitation, it follows that this delivers the full power of a Turing-complete environment into the hands of any attacker who finds a way of leveraging it through crafted inputs. Viewed from the venerable perspective of Least Privilege, Principle 1 states that com-putational power is privilege, and should be given as sparingly as any other kind of privilege to reduce the attack surface. We call this extension the “Minimal Computational Power Principle.” We note that recent developments in common protocols run contrary to these principles. In our opinion, this heralds a bumpy road ahead. In particular, HTML5+CSS is Turing-complete, whereas HTML4 was not. 原则一：“饿死图灵野兽”，请求并授予最小的计算能力** 计算能力是攻击面中一个重要且此前被忽视的方面。要避免将不必要的计算能力暴露给攻击者。输入语言的计算复杂度应仅达到绝对必要的程度，这样就能将解析器所需的计算能力降至最低。例如，如果不需要递归数据结构，那么在输入语言中就不应对其进行规定。解析器的计算能力不应超过实际所需的程度。例如，如果输入语言是确定性的上下文无关语言，那么解析器的计算能力不应超过确定性压栈自动机的计算能力。对于网络工程师而言，这一原则可以表述为如下内容： 解析器必须提供不超过解析其预期协议所需的最小计算能力 应当设计相应的协议，要求使用实现所需操作所需的最弱计算能力的解析器。 如果一种协议的实现方式超出了解析该协议输入数据所需的计算能力，那么这种实现方式就应当被视为存在缺陷。协议设计者应当将协议设计得尽可能弱化。任何一种输入语言计算强度的提升都应被视为赋予了额外的特权，从而增加了安全风险。因此，此类提升应当谨慎对待，需谨慎考虑，并应将其纳入正式的风险评估之中。至少，设计者应当遵循乔姆斯基层级结构（见侧栏内容）。大多数程序中的输入处理部分本质上就是图灵机，无论是否需要这种级别的计算能力都是如此。从之前所讨论的恶意计算的利用角度来看，由此可知这将把图灵完备环境的全部能力交到任何能够通过精心设计的输入来利用它的人手中。从“最小特权”这一古老的原则来看，第一条原则指出：计算能力即为特权，应当像给予任何其他类型的特权一样谨慎地分配，以减少攻击面。我们将这一扩展称为“最小计算能力原则”。我们注意到，当前通用协议的发展趋势与这些原则相悖。我们认为，这预示着未来将面临诸多困难。具体而言，HTML5 和 CSS 是图灵完备的，而 HTML4 并非如此。 Principle 2, Secure composition requires parser computational equiv-alence Composition is and will remain the principal tool of software engineering. Any principle that aims to address software insecurity must pass the test of being applicable to practical software composition, lest it forever remain merely theory. In particular, it should specify how to maintain security in the face of (inevitable) composition – including, but not limited to, distributed systems, use of libraries, and lower layer APIs. From our language-theoretic point of view, any composition that involves converting data structures to streams of bytes and back for communications between components necessarily relies for its security on the different components of the system performing equivalent computations on the input languages. However, computational equivalence of automata/machines accepting a language is a highly non-trivial language-theoretic problem that becomes Undecidable starting from non-deterministic context-free languages. The example of X.509 implementations ([101]) shows that this problem is directly related to the insecurity of distributed systems’ tasks. Moreover, undecidability essentially precludes construction of efficient code testing and algorithmic verification techniques and tools. On the relevance of Postel’s Law. This leads to a re-evaluation of Postel’s law and puts Dan Geer’s observations in “Vulnerable Compliance”[1] in solid theoretical perspective. Postel’s Robustness Principle (RFC 793), best known today as Postel’s Law, laid the foundation for an interoperable Internet ecosystem. In his specification of TCP, Postel advises “be conservative in what you do, be liberal in what you accept from others.” Despite being a description of the principle followed by TCP, this advice became widely accepted in the IETF and general Internet and software engineering communities as a core principle of protocol implementation. However, this policy maximizes interoperability at the unfortunate expense of consistent parser behavior, and thus at the expense of security. We argue in an upcoming article[102] that a strict reading of the Postel’s Principle should in fact discourage ambiguity and com-putational complexity in protocols. 原则 2：安全的组合需要解析器的计算等价性** 组合将是并将继续是软件工程的主要手段。任何旨在解决软件安全问题的原则都必须通过在实际软件组合中适用性的检验，否则它将永远只是理论而已。特别是，它应当明确在面对（不可避免的）组合时（包括但不限于分布式系统、库的使用以及底层 API）如何保持安全性。 从我们的语言理论角度来看，任何涉及将数据结构转换为字节流并将其在组件之间进行传输的操作，其安全性必然取决于系统中的各个组件对输入语言执行相同的操作。 然而，接受某种语言的自动机/机器之间的计算等价性是一个极其复杂的语言理论问题，从非确定性上下文无关语言开始，这个问题就变得无法解决（即变得不可判定）。 X.509 实现的实例 ([101]) 表明，这一问题与分布式系统任务的不安全性密切相关。此外，不可判定性从根本上阻碍了高效代码测试和算法验证技术及工具的构建。关于波斯特尔定律的相关性。 这促使人们重新审视波斯特尔定律，并将丹·吉尔在《脆弱的遵从性》[1]一书中所提出的观点置于坚实的理论框架之下。 波斯特尔的稳健性原则（RFC 793），如今人们更熟知它为波斯特尔定律，为一个可互操作的互联网生态系统奠定了基础。在对 TCP 的规范中，波斯特尔建议“在自己操作时要保守谨慎，在接受他人的信息时要开放包容。”尽管这是对 TCP 所遵循原则的描述，但这一建议在 IETF 和一般互联网及软件工程社区中被广泛接受，并成为协议实现的核心原则。 然而，这一政策在最大程度上实现了互操作性，但却以牺牲一致的解析器行为为代价，从而也牺牲了安全性。我们在即将发表的一篇文章[102]中指出，对普特尔原则的严格解读实际上应当抑制协议中的模糊性和计算复杂性。 10.1 为何安全组合很难 The second principle provides a powerful theoretical example of why composition – the developer’s and engineer’s primary strategy against complexity – is hard to do securely. Specifically, a composition of communicating program units must rely on computational equivalence of its input-handling routines for security (or even correctness when defined); yet such equivalence is undecidable for complex protocols (starting with those that need a Nondeterministic Pushdown Automaton to recognize their input language), and therefore cannot in practice be checked even for differing implementations of the same communication logic. Conversely, this suggests a principled approach for reducing insecurity of composition: keep the language of the messages exchanged by the components of a system to a necessary minimum of computational power required for their recognition. 第二个原则提供了一个强有力的理论例证，说明为何组合（开发者和工程师对抗复杂性的首要策略）难以安全地实施。具体而言，相互通信的程序单元的组合必须依赖于其输入处理程序的计算等价性以确保安全性（或者在定义时确保正确性）；然而，这种等价性对于复杂的协议来说是不可判定的（从那些需要非确定性推导自动机来识别其输入语言的协议开始），因此实际上即使对于相同通信逻辑的不同实现也无法进行检查。 相反，这表明了一种减少组合不安全性的原则性方法：将系统组件之间交换的消息的语言限制在识别这些消息所需的最小计算能力范围内。 10.2 与最小特权原则的相似之处 The understanding of “malicious computation” programmed by crafted inputs on the “weird machine” made of a target’s artifacts as a threat naturally complements and extends the“Least Privilege Principle” as a means of containing the attacker. In particular, just as the attacker should not be able to spread the compromise beyond the vulnerable unit or module, he should not be able to propagate it beyond the minimal computational power needed. This would curtail his ability to perform malicious computations. Thus, the “Least Privilege Principle” should be complemented by the “Minimal Compu-tational Power Principle”. This approach should be followed all the way from the application protocol to hardware. In fact, we envision hardware that limits itself from its current Turing machine form to weaker computational models according to the protocol parsing tasks it must perform, lending no more power to the parsing task than the corresponding language class requires – and therefore no more power for an attacker to borrow for exploit-programs in case of accidental exposure, starving the potential “weird machines” of such borrowed power. This restriction can be accomplished by reprogramming an FPGA to only provide the appropriate computational model, say, finite automaton or a pushdown automaton, to the task, with appropriate hardware-configured and enforced isolation of this environment from others (cf.[103]). 通过对目标所遗留物品中精心设计的输入所引发的“怪异机器”中的“恶意计算”现象的理解，将其视为一种威胁，这自然与“最小特权原则”相辅相成，并进一步拓展了这一原则，用以遏制攻击者。具体而言，正如攻击者不应能够将破坏行为扩展到易受攻击的单元或模块之外，他也不应能够将其传播到所需的最低计算能力之外。这样就能限制其进行恶意计算的能力。 因此，“最小特权原则”应当与“最小计算能力原则”相结合。这种原则应当贯穿从应用协议到硬件的整个过程。实际上，我们设想的硬件会根据其必须执行的协议解析任务，从当前的图灵机形式限制自身为更弱的计算模型，只为解析任务提供相应语言类所需的那么少的计算能力——从而在意外暴露的情况下，不让攻击者借取这种额外的计算能力来开发利用程序，剥夺潜在“奇异机器”获取此类借取能力的可能性。这种限制可以通过重新编程现场可编程门阵列（FPGA）来实现，使其仅向任务提供适当的计算模型，比如有限自动机或推导自动机，并通过适当的硬件配置和强制隔离该环境与其他环境相隔离（参见[103]）。 11 防御型识别器和协议 To complete our outlook, we must point to several successful examples of program and protocol design that we see as proceeding from and fulfilling related intuitions. The most recent and effective example of software specifically aimed to address the security risks of an input language in common Internet use is Blitzableiter by Felix ’FX’Lindner and Recurity Labs[80]. It takes on the task of safely recognizing Flash, arguably the most complex input language in common Internet use, due to two versions of bytecode allowed for backward compatibility and the complex SWF file format; predictably, Flash is a top exploitation vector with continually surfacing vulnerabilities. Blitzableiter (a pun on lightning rod) is an armored recognizer for Flash, engineered to maximally suppress implicit data and control flows that help attackers construct malicious computations. We note that that the approach of normalizing complex network protocols to remove both ambiguity and contsructs requiring excessive computation power (e.g.,[83]) is a close correlate, and works for the same reason. Another interesting example are the observations by D.J. Bernstein on the 10 years of qmail[3] We find several momentous insights in these, in particular avoiding parsing (i.e., in our terms, dealing with non-trivial input languages) whenever possible as a way of making progress in eliminating insecurity, pointing to hand-crafting input handling code for effi-ciency as a dangerous distraction, and his stress on using UNIX context isolation primitives as a way of enforcing explicit data flows (thus hobbling construction of malicious compu-tations). Interestingly, Bernstein also names the Least Privilege Principle — as currently understood — as a distraction; we argue that this principle needs to be updated rather than discarded, and see Bernstein’s insights as being actually in line with our proposed update. 为了完善我们的观点，我们必须列举出一些成功的项目和方案设计案例，这些案例我们认为是源自相关直觉并得以实现的。 目前针对常见互联网使用中输入语言的安全风险而专门开发的最有效软件的例子是费利克斯·“FX”·林德纳和瑞克蒂蒂尔实验室的“Blitzableiter”软件[80]。该软件承担了安全识别 Flash（可以说是在常见互联网使用中最为复杂的输入语言，因为允许使用两个版本的字节码以实现向后兼容性，并且 SWF 文件格式复杂）的任务；可以预见的是，Flash 是一个主要的漏洞利用目标，且不断出现新的漏洞。Blitzableiter（一个与避雷针有关的双关语）是一个为 Flash 设计的防护识别器，旨在最大程度地抑制隐含的数据和控制流，这些因素有助于攻击者构建恶意计算。 我们注意到，将复杂网络协议进行规范化处理以消除歧义并去除那些需要大量计算资源的元素（例如[83]中所述）这一方法与之密切相关，并且其原理相同。 另一个有趣的例子是 D.J. 伯恩斯坦对 qmail[3] 运行的 10 年的观察结果。我们在这些观察中发现了几个重要的见解，特别是避免进行解析（即按照我们的术语来说，处理非简单的输入语言）是消除不安全性的有效途径，这表明手工编写输入处理代码以提高效率是一种危险的干扰行为，而他强调使用 UNIX 上下文隔离原语来强制执行明确的数据流（从而阻碍恶意计算的构建）。有趣的是，伯恩斯坦还指出“最小特权原则”（按照目前的理解）是一种干扰因素；我们认为这一原则需要更新而非废弃，并认为伯恩斯坦的见解实际上与我们提出的更新方案是一致的。 12. 结论 Computer security is often portrayed as a never-ending arms race between attackers seeking to exploit weak points in software and defenders scrambling to defend regions of an ever-shifting battlefield. We hold that the front line is, instead, a bright one: the system’s security is defined by what computations can and cannot occur in it under all possible inputs. To approach security, the system must be analyzed as a recognizer for the language of its valid inputs, which must be clearly defined by designers and understood by developers. The computational power required to recognize the system’s valid inputs language (s) must be kept at a minimum when designing protocols. This serves to both reduce the power the attacker will be able to borrow, and help to check that handling of structured data across the system’s communicating components is computationally equivalent. The lack of such equivalence is a core cause of insecurity in network stacks and in other composed and distributed systems; undecidability of checking such equivalence for computationally demanding (or ambiguously specified) protocols is what makes securing composed systems hard or impossible in both theory and practice. We state simple and understandable but theoretically fundamental priciples that could make protection from unexpected computations a reality, if followed in design of protocols and systems. Furthermore, we suggest that in future designs, hardware protections should be put in place to control and prevent exposure of unnecessary computational power to attackers. 计算机安全通常被描绘成一场永无止境的“军备竞赛”，其中攻击者试图利用软件中的漏洞进行攻击，而防御者则竭力在不断变化的战场上进行防御。但我们认为，真正的前线其实是一条清晰明确的防线：系统的安全性取决于在所有可能的输入条件下，该系统中能够和不能进行的计算。要实现安全，就必须将系统视为一种针对其有效输入语言的识别器，并且这种语言必须由设计者明确界定，同时也要被开发人员理解。 在设计协议时，必须将识别系统有效输入语言所需的计算能力控制在最低限度。这样做既能减少攻击者能够利用的计算能力，又能帮助检查系统各通信组件之间对结构化数据的处理在计算上是否等效。这种等效性的缺失是网络栈以及其他组合式和分布式系统中不安全性的核心原因；对于计算要求高（或定义模糊）的协议，检查这种等效性的不可确定性使得确保组合式系统的安全在理论和实践中都变得困难甚至不可能。 我们提出了简单易懂但具有理论基础的原理，这些原理若能在协议和系统的设计中得到遵循，就能使防范意外计算成为可能。此外，我们建议在未来的设计中，应设置硬件保护措施，以控制并防止不必要的计算能力被攻击者获取。 13. 致谢 The authors would like to thank Ed Feustel for his observations on the security of composed systems; Dan Kaminsky, for his collaboration in the analysis of flaws in ASN. 1 parsers; Andreas Bogk, Rik Farrow, Dan McCardle, James Oakley, Frank Piessens, and Sean W. Smith for helpful suggestions on earlier versions of this paper, and Nikita Borisov, Nessim Kisserli, Felix Lindner, Doug McIlroy, and David Molnar, for their insightful conversations during the process of this research. The work of Len Sassaman was supported in part by the Research Council K.U.Leuven: GOA TENSE (GOA/11/007), and by the IAP Programme P6/26 BCRYPT of the Belgian State (Belgian Science Policy). 作者们要感谢 Ed Feustel 对复合系统安全性的观察；感谢 Dan Kaminsky 在分析 ASN. 1 解析器缺陷方面的合作；感谢 Andreas Bogk、Rik Farrow、Dan McCardle、James Oakley、Frank Piessens 和 Sean W. Smith 对本文早期版本的有益建议；以及感谢 Nikita Borisov、Nessim Kisserli、Felix Lindner、Doug McIlroy 和 David Molnar 在研究过程中提供的深入见解。 伦·萨萨曼的工作部分得到了鲁汶大学研究委员会的支持：GOA TENSE (GOA/11/007)，以及比利时国家（比利时科学政策）的 IAP 计划 P6/26 BCRYPT 的支持。 参考文献 [1] 丹·吉尔，“脆弱的合规性”，《USENIX 杂志》，第 35 卷，第 6 期，2010 年 12 月。 [2] Felix ’FX’ Lindner，“被破坏的观察者效应”，McAfee 安全期刊，第 6 卷，2010 年，Dan Sommer（编辑）。 [3] Daniel J. Bernstein，“十年 qmail 1.0 后的安全思考”，2007 年 ACM 计算机安全架构研讨会论文集，纽约，美国，2007 年，CSAW ’07，第 1-10 页，ACM。 [4] Leslie Lamport，“证明多进程程序的正确性”，IEEE 软件工程学报，第 3 卷，第 125-143 页，1977 年。 [5] Ranjit Jhala 和 Rupak Majumdar，“软件模型检查”，ACM 计算机调查，第 41 卷，第 4 期，2009 年。 [6] H. Finney，“基于实现错误的 Bleichenbacher 的 RSA 签名伪造”，2006 年 8 月。 [7] Tetsuya Izu，Takeshi Shimoyama 和 Masahiko Takenaka，“扩展 Bleichenbacher 的伪造攻击”，《信息处理杂志》，第 16 卷，第 122-129 页，2008 年 9 月。 [8] Dan Kaminsky、Meredith L. Patterson 和 Len Sassaman，“PKI Layer Cake：针对全球 X.509 基础设施的新碰撞攻击”，在《金融密码学》2010 年，第 289-303 页，Springer 出版。 [9] G´eraud S´enizergues，“L (A)=L (B)? 完全形式系统的可判定性结果”，《理论计算机科学》，第 251 卷，第 1-2 期，第 1-166 页，2001 年。 [10] Michael Sipser，《计算理论导论》，第二版，国际版，汤普森课程技术出版社，2006 年。 [11] 斯蒂芬·凯普瑟，“XSLT 和 XQuery 图灵完备性的简单证明”，在《极端标记语言》中，2004 年。 [12] Ruhsan Onder 和 Zeki Bayram，“XSLT 2.0 版本是图灵完备的：一个纯粹基于转换的证明”，收录于《自动机的实现与应用》，Oscar Ibarra 和 Hsu-Chun Yen 编辑，2006 年，计算机科学讲义第 4094 卷，第 275-276 页，Springer Berlin/ Heidelberg。 [13] 艾利·福克斯-爱泼斯坦，“抽象机器的实验”，https://github.com/elitheeli/oddities，2011 年 3 月。 [14] Mathew Cook，“基本元胞自动机的通用性”，《复杂系统》，第 15 卷，第 1 期，第 1-40 页，2004 年。 [15] Julia Wolf，“OMG-WTF-PDF”，第 27 届混沌计算机大会，2010 年 12 月。 [16] 尼尔斯·安德斯·丹尼尔森，“总解析器组合子”，在 2010 年第 15 届 ACM SIGPLAN 国际函数式编程会议上，ICFP '10，第 285-296 页。 [17] A. Koprowski 和 H. Binsztok，“TRX：一个形式验证的解析器解释器”，在《编程语言和系统》中，第 6012 卷，LNCS，第 345-365 页。Springer，2010 年。 [18] 汤姆·里奇，“所有上下文无关语法的简单、功能齐全、可靠且完整的解析”，提交出版，2011 年。 [19] F.B. Schneider，J.G. Morrisett 和R. Harper，“基于语言的安全方法”，收录于《信息学- 10 年前。10 年后》。2001 年，Springer-Verlag 出版。 [20] 诺姆·乔姆斯基，“论语法的某些形式属性”，《信息与计算/信息与控制》，第 2 卷，第 137-167 页，1959 年。 [21] Tim Berners-Lee 和 Noah Mendelsohn，“最小权力法则”，标签查找，W3C，2006 年，http://www.w3.org/2001/tag/doc/leastPower.html。 [22] 罗伯特·J·汉森和梅雷迪思·L·帕特森，“枪支与黄油：迈向输入验证的形式公理”，《黑帽简报会议论文集》，2005 年。 [23] 西摩尔·金斯堡和希拉·格雷巴赫，“确定性上下文无关语言”，在 1965 年第 6 届开关电路理论与逻辑设计研讨会上发表，第 203-220 页。 [24] 崔卫东、Kannan Jayanthkumar 和 Helen J. Wang，“Discoverer：从网络跟踪中自动进行协议逆向工程”，在 USENIX 安全研讨会，2007 年。 [25] R. Fielding，J. Gettys，J. Mogul，H. Frystyk，L. Masinter，P. Leach 和T. Berners-Lee，“超文本传输协议——HTTP/1.1”，请求评论：2616，1999 年 6 月。 [26] 信息科学研究所，“互联网协议”，请求评论：791，1981 年 9 月。 [27] Wajid Ali、Kanwal Sultana 和 Sophia Pervez，“关于 JavaScript 可视化编程扩展的研究”，《国际计算机应用杂志》，第 17 卷，第 1 期，第 13-19 页，2011 年 3 月。 [28] 保罗·W·亚伯拉罕斯，“ALGOL 60 及相关语言中悬空 else 的最终解决方案”，《通信 ACM》，第 9 卷，第 679-682 页，1966 年 9 月。 [29] 唐纳德·E·克努特，“从左到右的语言翻译”，《信息与控制》，第 8 卷，第 6 期，第 607-639 页，1965 年。 [30] H. J. S. Basten，“上下文无关语法的歧义检测方法的可用性”，《电子理论计算机科学笔记》，第 238 卷，第 35-46 页，2009 年 10 月。 [31] 罗伯特·W·弗洛伊德，“短语结构语言中的歧义性”，《ACM 通讯》，第 5 卷，第 526 页及以后，1962 年 10 月。 [32] 克劳德·E·香农，“通信的数学理论”，《贝尔系统技术杂志》，第 27 卷，第 379-423 页，1948 年 7 月。 [33] 威尔伯·施拉姆，《传播的过程与效果》，章节“传播如何运作”，伊利诺伊大学出版社，1954 年。 [34] D.K. Berlo，《传播过程》，霍尔特、莱因哈特和温斯顿，1960 年。 [35] C.A.R. Hoare，“计算机编程的公理基础”，《ACM 通讯》，第 12 卷，第 10 期，第 576-583 页，1969 年。 [36] H. P. Grice，《语言之道研究》，哈佛大学出版社，1989 年。 [37] B. Meyer，“应用‘契约设计’”，《计算机》，第 25 卷，第 40-51 页，1992 年 10 月。 [38] “CWE-77”，常见弱点枚举，2008 年 7 月。 [39] Tim Berners-Lee、Roy Fielding 和 Larry Masinter，“RFC 3986，统一资源标识符（URI）：通用语法”，请求评论：3986，2005 年 1 月。 [40] Dave Raggett、Arnaud Le Hors 和 Ian Jacobs，“HTML 文档中的表单”，HTML 4.01 规范，1999 年 12 月。 [41] Luca Carettoni 和 Stefano di Paola，“HTTP 参数污染”，OWASP 欧洲波兰，2009 年。 [42] Tadeusz Pietraszek 和 Chris Vanden Berghe，“通过上下文敏感的字符串评估防御注入攻击”，在 RAID，2005 年，第 124-145 页。 [43] William G.J. Halfond，Jeremy Viegas 和 Alessandro Orso，“SQL 注入攻击及其对策的分类”，在 2006 年 3 月的 IEEE 国际安全软件工程研讨会上发表。 [44] rix，“编写 ia32 字母数字 Shellcode”，Phrack 57，2001 年 8 月。 [45] Nergal，“高级返回到 lib © 的利用：PaX 案例研究”，Phrack 58，2001 年 12 月。 [46] Ryan Roemer、Erik Buchanan、Hovav Shacham 和 Stefan Savage，“面向返回的编程：系统、语言和应用”，2009 年，正在审阅中。 [47] Hovav Shacham，“骨头上无辜肉体的几何学：无需函数调用的返回到 libc（在 x86 上）”，收录于 CCS 会议论文集，2007 年。 [48] Tyler Durden，“绕过 PaX ASLR 保护”，Phrack 59，2002 年 7 月。 [49] Aleph One，“为了乐趣和利润而破坏堆栈”，Phrack 49，1996 年 8 月。 [50] MaXX，“Vudo malloc 技巧”，Phrack 57：8，http://phrack.org/issues.html? issue=57id=8。 [51] 匿名作者，“从前有个 free ()”，Phrack 57：9，http://phrack.org/issues.html? issue=57id=9。 [52] jp，“高级 Doug Lea 的 malloc 漏洞利用”，《Phrack 杂志》，第 61 卷，第 6 期，2003 年 8 月。 [53] Tim Newsham，“格式字符串攻击”，http://www.thenewsh.com/newsham/format-string-attacks.pdf，2000 年 9 月。 [54] “CVE-2005-3962”，国家漏洞数据库，2005 年 12 月。 [55] “CVE-2011-1153”，国家漏洞数据库，2011 年 3 月。 [56] F. Valeur，D. Mutz 和G. Vigna，“基于学习的 SQL 攻击检测方法”，在 2005 年 7 月的 DIMVA 会议论文集中，第 123-140 页。 [57] 格雷戈里·T·布埃勒、布鲁斯·W·韦德和保罗·A·G·西维洛蒂，“使用解析树验证来防止 SQL 注入攻击”，在 2005 年国际软件工程与中间件研讨会论文集，第 106-113 页。 [58] Prithvi Bisht，P. Madhusudan 和V. N. Venkatakrishnan，“CANDID：动态候选评估以自动防止 SQL 注入攻击”，ACM Trans. Inf. Syst. Secur., vol. 13, no. 2, pp. 1–39, 2010。 [59] 苏振东和加里·瓦瑟曼，“Web 应用程序中命令注入攻击的本质”，在第 33 届程序语言原理研讨会上，2006 年，第 372-382 页。 [60] William G. J. Halfond 和 Alessandro Orso，“使用 AMNESIA 防止 SQL 注入攻击”，在第 28 届国际软件工程会议论文集，2006 年，第 795-798 页。 [61] Gary Wassermann，Carl Gould，Zhendong Su 和 Premkumar Devanbu，“数据库应用程序中动态生成查询的静态检查”，2007 年。 [62] Ke Wei，M. Muthuprasanna 和 Suraj Kothari，“防止存储过程中的 SQL 注入攻击”，在澳大利亚软件工程会议论文集，2006 年，第 191-198 页。 [63] M. Muthuprasanna，Ke Wei 和 Suraj Kothari，“消除 SQL 注入攻击——一种透明的防御机制”，在 2006 年第八届 IEEE 国际网站进化研讨会上发表，第 22-32 页。 [64] Carl Gould，Zhendong Su 和 Premkumar Devanbu，“JDBC Checker：一个用于 SQL/JDBC 应用程序的静态分析工具”，在 2004 年国际软件工程会议上发表，第 697-698 页。 [65] A.S. Christensen，A. Møller 和M.I. Schwartzbach，“精确的字符串表达式分析”，在 2003 年第 10 届国际静态分析研讨会论文集中，第 1-18 页。 [66] San-Tsai Sun 和 Konstantin Beznosov，“为现有 Web 应用程序添加有效的动态保护以抵御 SQL 注入攻击”，《国际安全软件工程杂志》，第 1 卷，第 20-40 页，2010 年 1 月。 [67] W.G.J. Halfond 和 A. Orso，“AMNESIA：用于中和 SQL 注入攻击的分析和监控”，ASE 2005，美国加利福尼亚州长滩，2005 年 11 月。 [68] W. Halfond，A. Orso 和P. Manolios，“使用正向污染和语法感知评估来对抗 SQL 注入攻击”，在 FSE 2006，2006 年 11 月，第 175-185 页。 [69] P.Y. Gibello，“ZQL：一个 Java SQL 解析器”，http://zql.sourceforge.net/，2002 年。 [70] Konstantinos Kemalis 和 Theodores Tzouramanis，“SQL-IDS：一种基于规范的 SQL 注入检测方法”，在应用计算研讨会论文集，2008 年，第 2153-2158 页。 [71] 刘安义、袁毅、Duminda Wijesekera 和 Angelos Stavrou，“SQLProb：一种基于代理的防止 SQL 注入攻击的架构”，在 ACM 应用计算研讨会上，2009 年，第 2054-2061 页。 [72] “CVE-2006-2313”，国家漏洞数据库，2006 年 5 月。 [73] “CVE-2006-2314”，国家漏洞数据库，2006 年 5 月。 [74] 唐纳德·克努特，“上下文无关语言的语义”，《数学系统理论》，第 2 卷，第 127-145 页，1968 年。 [75] B. Kaliski，“PKCS #1 ：RSA 加密”，1998 年 3 月，http://tools.ietf.org/html/rfc2313。 [76] Michael Howard、Jon Pincus 和 Jeannette Wing，“测量相对攻击面”，收录于《21 世纪计算机安全》，D. T. Lee、S. P. Shieh 和J. D. Tygar 编，第 109-137 页。Springer US，2005 年。 [77] 彼得·埃克斯利，“你的网络浏览器有多独特？”，技术报告，电子前沿基金会，2009 年。 [78] 尼克·马修森和罗杰·丁格莱恩，“实用流量分析：扩展和抵抗统计披露”，在 2004 年 5 月的隐私增强技术研讨会（PET 2004）论文集中，LNCS 第 3424 卷，第 17-34 页。 [79] 理查德·克莱顿，“混合内容屏蔽系统的失败”，载于 2005 年第五届隐私增强技术研讨会，PET 2005，2005 年，第 1 页。 [80] Felix Lindner，“被妥协的观察者效应”，McAfee 安全期刊，第 6 卷，2010 年，Dan Sommer（编辑）。 [81] 托马斯·普塔切克、蒂莫西·纽沙姆和霍默·辛普森，“插入、逃避和拒绝服务：规避网络入侵检测”，技术报告，Secure Networks 公司，1998 年。 [82] Ofir Arkin，“扫描中 ICMP 的使用，完整的技术知识”，技术报告，Sys-Security Group，2001 年，版本 3.0。 [83] Mark Handley、Vern Paxson 和 Christian Kreibich，“网络入侵检测：规避、流量规范化和端到端协议语义”，在第 10 届 USENIX 安全研讨会论文集，美国加利福尼亚州伯克利，2001 年，SSYM’01，第 9-9 页，USENIX 协会。 [84] Umesh Shankar 和 Vern Paxson，“主动映射：在不改变流量的情况下抵抗 NIDS 规避”，IEEE 安全与隐私研讨会，2003 年，第 44-61 页。 [85] Sumit Siddharth，“重新审视规避 NIDS”，http://www.symantec.com/connect/articles/evading-nids-revisited，2005 年 12 月（2010 年 11 月更新）。 [86] Tal Garfinkel，“陷阱和坑洞：基于系统调用拦截的安全工具的实际问题”，在 2003 年 2 月的网络与分布式系统安全研讨会论文集中。 [87] S. A. Hofmeyr，Anil Somayaji 和S. Forrest，“使用系统调用序列的入侵检测系统”，《计算机安全杂志》，第 6 卷，第 3 期，第 151-180 页，1998 年。 [88] Henry H. Feng，Oleg Kolesnikov，Prahlad Fogla，Wenke Lee 和 Weibo Gong，“使用调用栈信息进行异常检测”，在 2003 年 IEEE 安全与隐私研讨会上的论文集，2003 年 5 月。 [89] David Wagner 和 Paolo Soto，“基于主机的入侵检测系统的模仿攻击”，在 ACM 计算机和通信安全会议 (CCS) 的论文集中，2002 年 11 月。 [90] 卡罗尔·泰勒和卡莉·盖茨，“挑战异常检测范式：一次挑衅性的讨论”，在第 15 届新安全范式研讨会（NSPW）的论文集中，2006 年 9 月，第 21-29 页。 [91] R. Sommer 和 V. Paxson，“超越封闭世界：关于使用机器学习进行网络入侵检测”，在 2010 年 5 月的 IEEE 安全与隐私研讨会上发表。 [92] A. Somayaji，S. Hofmeyer 和S. Forrest，“计算机免疫系统的原则”，在 1998 年新安全范式研讨会（NPSW）的论文集中，第 75-82 页。 [93] A. Somayaji 和 S. Forrest，“使用系统调用延迟的自动化响应”，在第九届 USENIX 安全研讨会论文集，2000 年 8 月。 [94] Fred B. Schneider，“可执行的安全策略”，ACM Trans. Inf. Syst. Secur., 第 3 卷，第 30-50 页，2000 年 2 月。 [95] W. Swierstra，“为什么属性文法很重要”，《Monad Reader》，2005 年 7 月。 [96] K. Bhargavan，C. Fournet 和A.D. Gordon，“通过类型化对安全协议代码进行模块化验证”，Sigplan Notices，第 45 卷，2010 年。 [97] S. Chaki 和 A. Datta，“ASPIER：一个用于验证安全协议实现的自动化框架。”，在 CSF，2009 年，第 172-185 页。 [98] 托马斯·杜利恩，“利用与状态机：重新审视‘奇怪机器’的编程”，http://www.immunityinc.com/infiltrate/presentations/Fundamentals_of_exploitation_revisited.pdf，2011 年 4 月，渗透会议。 [99] Sergey Bratus，Michael E. Locasto，Meredith L. Patterson，Len Sassaman 和 Anna Shubina，“漏洞编程：从缓冲区溢出到‘奇怪机器’和计算理论”，；login，2011 年 12 月。 【100】 M. Bishop 和 D. Bailey，“漏洞分类法的批判性分析”，技术报告 CSE-96-11，加州大学戴维斯分校计算机科学系，戴维斯，加利福尼亚州 95616-8562，1996 年 9 月。 [101] Dan Kaminsky、Len Sassaman 和 Meredith Patterson，“PKI Layer Cake：针对全球X.509 CA 基础设施的新碰撞攻击”，Black Hat USA，2009 年 8 月，http://www.cosic.esat.kuleuven.be/publications/article-1432.pdf。 [102] Len Sassaman、Meredith L. Patterson 和 Sergey Bratus，“Postel 的健壮性原则的补丁”，提交给 IEEE 安全与隐私杂志，2011 年。 [103] Sergey Bratus，Michael E. Locasto，Ashwin Ramaswamy 和 Sean W. Smith，“硬件辅助可信计算策略的新方向（立场文件）”，2008 年。","tags":["形式语言","形式系统","比特币"],"categories":["论文"]},{"title":"朋友文章","path":"/friends/rss/index.html","content":""},{"title":"Adocs 项目系统文档","path":"/wiki/a-docs/index.html","content":"这里是项目文档的首页"},{"title":"Adocs 项目系统文档2","path":"/wiki/a-docs/examples.html","content":"这里是examples的具体内容"},{"title":"Adocs 项目系统文档 之 pages","path":"/wiki/a-docs/pages.html","content":"这里是pages"},{"title":"探索","path":"/explore/index.html","content":"… TODO:等待完善"},{"title":"Adocs 项目系统文档3","path":"/wiki/a-docs/releases.html","content":"这里是releases"},{"title":"Adocs 项目系统文档 4","path":"/wiki/a-docs/theme-settings.html","content":"这里是theme-settings"},{"title":"友链","path":"/friends/index.html","content":"友链关于致敬生命在远离平衡态的负熵孤岛中产生。 [2023-12] 友链失联了怎么办? 添加友链后如果网站长期无法访问，可能会被取消友链！如果您的网站恢复了，可以在申请友链时创建的那条 issue 中评论告知。 朋友们近期的文章 如何交换友链？ 您的网站应满足以下全部条件： 安全合规：合法的、非营利性、无木马植入的 HTTPS 站点。 非空壳网站：网站内发布至少 五篇 原创文章，内容题材不限。 我们需要有一定的有效互动： 先友后链：与博主有至少 半年 的有效互动，例如 issue 或者评论留言。 [2023-12] 友链申请条件变更说明 降低了对商业广告的要求，可以有但是不能太多。提高了「有效互动」的定义：5次更改为半年。 我已满足全部条件，快告诉我如何交换友链！ 如果您没有满足上述条件，即时提交了申请也不会通过哦～ 第一步：新建 Issue新建 GitHub Issue 按照模板格式填写并提交。为了提高图片加载速度，建议优化头像：打开 压缩图 上传自己的头像，将图片尺寸调整到 144px 后下载。将压缩后的图片上传到 去不图床 或者其它稳定的图床并使用此图片链接作为头像。第二步：添加友链并等待管理员审核请添加本站到您的友链中：title: xxxurl: https://xxx.comavatar: screenshot: 待管理员审核通过，添加了 active 标签后，回来刷新即可生效。如果您需要更新自己的友链，请直接修改 issue 内容，大约 3 分钟内生效，无需等待博客重新部署。 -->"}]